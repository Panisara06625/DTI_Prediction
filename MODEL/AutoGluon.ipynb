{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c933e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdb291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset you created\n",
    "df = pd.read_csv(\"descriptor_based_dataset.csv\")\n",
    "df = df.copy()\n",
    "df = df[df['Kd'].notnull()]  # Remove NaN\n",
    "df = df[np.isfinite(df['Kd'])]  # Remove inf/-inf\n",
    "\n",
    "# Split data into train/test\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c1a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250506_124642\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          12\n",
      "Memory Avail:       0.42 GB / 7.42 GB (5.6%)\n",
      "Disk Space Avail:   15.41 GB / 262.54 GB (5.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "2025-05-06 19:46:43,994\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-05-06 19:46:53,714\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_124642\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Beginning AutoGluon training ... Time limit = 884s\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m AutoGluon will save models to \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_124642\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Train Data Rows:    43442\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Train Data Columns: 9\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Label Column:       Kd\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tAvailable Memory:                    655.47 MB\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.98 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t9 features in original data used to generate 9 features in processed data.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTrain Data (Processed) Memory Usage: 2.98 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 588.80s of the 883.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.6517\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 585.63s of the 880.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.6036\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 585.30s of the 879.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.11%)\n",
      "\u001b[36m(_ray_fit pid=6948)\u001b[0m Warning: Low available memory may cause OOM error if training continues\n",
      "\u001b[36m(_ray_fit pid=6948)\u001b[0m Estimated GBM model size: 0 MB\n",
      "\u001b[36m(_ray_fit pid=6948)\u001b[0m Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\n",
      "\u001b[36m(_ray_fit pid=6948)\u001b[0m Available Memory: 126 MB\n",
      "\u001b[36m(_ray_fit pid=59120)\u001b[0m Available Memory: 126 MB\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-2.4576\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t2.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 573.60s of the 868.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=9.73%)\n",
      "\u001b[36m(_ray_fit pid=77860)\u001b[0m Warning: Low available memory may cause OOM error if training continues\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77860)\u001b[0m Estimated GBM model size: 0 MB\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77860)\u001b[0m Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77860)\u001b[0m Available Memory: 116 MB\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-2.4257\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t3.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 558.10s of the 852.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 119 due to low memory. Expected memory usage reduced from 37.61% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=80756)\u001b[0m Warning: Low available memory may cause OOM error if training continues\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=80756)\u001b[0m Estimated GBM model size: 0 MB\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=80756)\u001b[0m Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=80756)\u001b[0m Available Memory: 208 MB\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.1706\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t7.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t1.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 548.59s of the 843.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.04% memory usage per fold, 54.07%/80.00% total).\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=27.04%)\n",
      "\u001b[36m(_ray_fit pid=81548)\u001b[0m \tRan out of time, early stopping on iteration 5728.\n",
      "\u001b[36m(_ray_fit pid=29732)\u001b[0m \tRan out of time, early stopping on iteration 3308.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=50400)\u001b[0m \tRan out of time, early stopping on iteration 3414.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=78912)\u001b[0m \tRan out of time, early stopping on iteration 2192.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.2165\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t461.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 81.56s of the 376.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 106 due to low memory. Expected memory usage reduced from 42.38% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=76232)\u001b[0m \tRan out of time, early stopping on iteration 1578.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.1622\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t7.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t4.68s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 67.76s of the 362.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.04%)\n",
      "\u001b[36m(_ray_fit pid=79252)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n",
      "\u001b[36m(_ray_fit pid=47948)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 8)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.7823\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t115.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t3.44s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=77060)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 220.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.375, 'RandomForestMSE_BAG_L1': 0.312, 'CatBoost_BAG_L1': 0.312}\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.12\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 219.08s of the 218.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.86%)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.1064\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t56.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t2.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 141.03s of the 140.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.18%)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.1056\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t32.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.8s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 73.16s of the 72.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 161 due to low memory. Expected memory usage reduced from 27.91% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tWarning: Reducing model 'n_estimators' from 161 -> 43 due to low time. Expected time usage reduced from 268.9s -> 73.0s...\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.1715\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t20.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t2.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 49.23s of the 49.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.89% memory usage per fold, 79.56%/80.00% total).\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=19.89%)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tTime limit exceeded... Skipping CatBoost_BAG_L2.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -10.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.381, 'LightGBM_BAG_L2': 0.333, 'RandomForestMSE_BAG_L2': 0.19, 'CatBoost_BAG_L1': 0.048, 'ExtraTreesMSE_BAG_L1': 0.048}\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t-1.0984\t = Validation score   (-mean_squared_error)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t1.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m AutoGluon training complete, total runtime = 896.03s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 688.3 rows/s (5431 batch size)\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_124642\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=47624)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val         eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        LightGBMXT_BAG_L2      -1.094794  -1.106423  mean_squared_error       42.638548      12.030820  656.224502                 1.758274                2.267011          56.573816            2       True         10\n",
      "1      WeightedEnsemble_L3      -1.096782  -1.098430  mean_squared_error       45.730151      15.265163  710.917025                 0.064082                0.008356           1.994171            3       True         13\n",
      "2          LightGBM_BAG_L2      -1.101119  -1.105612  mean_squared_error       42.391422      10.568542  631.731675                 1.511148                0.804733          32.080989            2       True         11\n",
      "3      WeightedEnsemble_L2      -1.114316  -1.120031  mean_squared_error       14.787813       5.972065  478.457210                 0.187140                0.006999           0.881444            2       True          9\n",
      "4   RandomForestMSE_BAG_L2      -1.142209  -1.171548  mean_squared_error       42.396647      12.185063  620.268050                 1.516373                2.421254          20.617363            2       True         12\n",
      "5     ExtraTreesMSE_BAG_L1      -1.148861  -1.162153  mean_squared_error        1.814714       4.684909    7.768789                 1.814714                4.684909           7.768789            1       True          7\n",
      "6   RandomForestMSE_BAG_L1      -1.150582  -1.170640  mean_squared_error        2.230592       1.047540    7.848619                 2.230592                1.047540           7.848619            1       True          5\n",
      "7          CatBoost_BAG_L1      -1.188232  -1.216514  mean_squared_error       10.555366       0.232617  461.958358                10.555366                0.232617         461.958358            1       True          6\n",
      "8    KNeighborsDist_BAG_L1      -1.607289  -1.603646  mean_squared_error        0.356043       0.138951    0.121748                 0.356043                0.138951           0.121748            1       True          2\n",
      "9    KNeighborsUnif_BAG_L1      -1.663050  -1.651749  mean_squared_error        0.784237       0.127521    0.118966                 0.784237                0.127521           0.118966            1       True          1\n",
      "10  NeuralNetFastAI_BAG_L1      -1.711083  -1.782254  mean_squared_error       20.228912       3.439333  115.742587                20.228912                3.439333         115.742587            1       True          8\n",
      "11         LightGBM_BAG_L1      -2.412041  -2.425720  mean_squared_error        1.068983       0.043350    3.710326                 1.068983                0.043350           3.710326            1       True          4\n",
      "12       LightGBMXT_BAG_L1      -2.445044  -2.457580  mean_squared_error        3.841427       0.049588    2.381294                 3.841427                0.049588           2.381294            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t964s\t = DyStack   runtime |\t2636s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2636s\n",
      "AutoGluon will save models to \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_124642\"\n",
      "Train Data Rows:    48873\n",
      "Train Data Columns: 9\n",
      "Label Column:       Kd\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1715.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\t0.5s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.36 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1756.07s of the 2634.63s of remaining time.\n",
      "\t-1.6396\t = Validation score   (-mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1734.36s of the 2612.92s of remaining time.\n",
      "\t-1.5804\t = Validation score   (-mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1731.99s of the 2610.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.65%)\n",
      "\t-1.4448\t = Validation score   (-mean_squared_error)\n",
      "\t228.65s\t = Training   runtime\n",
      "\t321.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1353.86s of the 2232.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.90%)\n",
      "\t-1.54\t = Validation score   (-mean_squared_error)\n",
      "\t153.71s\t = Training   runtime\n",
      "\t180.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1100.63s of the 1979.19s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 96 due to low memory. Expected memory usage reduced from 46.64% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1515\t = Validation score   (-mean_squared_error)\n",
      "\t14.64s\t = Training   runtime\n",
      "\t4.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1079.55s of the 1958.12s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.06% memory usage per fold, 58.11%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=29.06%)\n",
      "\t-1.2169\t = Validation score   (-mean_squared_error)\n",
      "\t1036.12s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 10.69s of the 889.25s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 69 due to low memory. Expected memory usage reduced from 64.69% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 25.0s to train, which exceeds the maximum time limit of 10.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 7.21s of the 885.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.39%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "2025-05-06 20:33:03,030\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-06 20:33:03,072\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-06 20:33:03,112\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 821.55s of remaining time.\n",
      "2025-05-06 20:33:04,082\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-06 20:33:04,120\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-06 20:33:04,145\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.588, 'CatBoost_BAG_L1': 0.353, 'KNeighborsDist_BAG_L1': 0.059}\n",
      "\t-1.1161\t = Validation score   (-mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 819.67s of the 819.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.39%)\n",
      "\t-1.2603\t = Validation score   (-mean_squared_error)\n",
      "\t54.16s\t = Training   runtime\n",
      "\t2.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 731.39s of the 731.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.30%)\n",
      "\t-1.8879\t = Validation score   (-mean_squared_error)\n",
      "\t26.67s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 666.71s of the 666.61s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 118 due to low memory. Expected memory usage reduced from 38.1% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1205\t = Validation score   (-mean_squared_error)\n",
      "\t43.13s\t = Training   runtime\n",
      "\t6.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 614.55s of the 614.45s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.96% memory usage per fold, 57.92%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=28.96%)\n",
      "2025-05-06 20:40:02,853\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-1.0946\t = Validation score   (-mean_squared_error)\n",
      "\t313.04s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 272.76s of the 272.66s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 72 due to low memory. Expected memory usage reduced from 62.05% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1271\t = Validation score   (-mean_squared_error)\n",
      "\t8.14s\t = Training   runtime\n",
      "\t3.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 258.94s of the 258.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.69%)\n",
      "\t-1.0963\t = Validation score   (-mean_squared_error)\n",
      "\t268.82s\t = Training   runtime\n",
      "\t3.45s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -47.70s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.36, 'RandomForestMSE_BAG_L2': 0.24, 'CatBoost_BAG_L2': 0.24, 'ExtraTreesMSE_BAG_L2': 0.16}\n",
      "\t-1.0832\t = Validation score   (-mean_squared_error)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2686.89s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 12.0 rows/s (6110 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_124642\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-1.083170</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>522.601166</td>\n",
       "      <td>2070.606627</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>3.060996</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-1.094616</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>509.099316</td>\n",
       "      <td>1747.464475</td>\n",
       "      <td>0.746022</td>\n",
       "      <td>313.035524</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-1.096302</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>511.803428</td>\n",
       "      <td>1703.245174</td>\n",
       "      <td>3.450133</td>\n",
       "      <td>268.816223</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.116098</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>6.261970</td>\n",
       "      <td>1053.284036</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>1.786626</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-1.120546</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>514.881524</td>\n",
       "      <td>1477.557170</td>\n",
       "      <td>6.528230</td>\n",
       "      <td>43.128219</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-1.127092</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>511.873779</td>\n",
       "      <td>1442.565665</td>\n",
       "      <td>3.520484</td>\n",
       "      <td>8.136714</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-1.151460</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>4.241178</td>\n",
       "      <td>14.643198</td>\n",
       "      <td>4.241178</td>\n",
       "      <td>14.643198</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-1.216908</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.278060</td>\n",
       "      <td>1036.116752</td>\n",
       "      <td>1.278060</td>\n",
       "      <td>1036.116752</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-1.260292</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>511.187376</td>\n",
       "      <td>1488.593170</td>\n",
       "      <td>2.834081</td>\n",
       "      <td>54.164219</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-1.444756</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>321.162151</td>\n",
       "      <td>228.648296</td>\n",
       "      <td>321.162151</td>\n",
       "      <td>228.648296</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-1.539981</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>180.046129</td>\n",
       "      <td>153.706756</td>\n",
       "      <td>180.046129</td>\n",
       "      <td>153.706756</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-1.580387</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.740592</td>\n",
       "      <td>0.737460</td>\n",
       "      <td>0.740592</td>\n",
       "      <td>0.737460</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-1.639574</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.576489</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.576489</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-1.887899</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>508.786626</td>\n",
       "      <td>1461.103691</td>\n",
       "      <td>0.433331</td>\n",
       "      <td>26.674741</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val         eval_metric  pred_time_val  \\\n",
       "0      WeightedEnsemble_L3  -1.083170  mean_squared_error     522.601166   \n",
       "1          CatBoost_BAG_L2  -1.094616  mean_squared_error     509.099316   \n",
       "2   NeuralNetFastAI_BAG_L2  -1.096302  mean_squared_error     511.803428   \n",
       "3      WeightedEnsemble_L2  -1.116098  mean_squared_error       6.261970   \n",
       "4   RandomForestMSE_BAG_L2  -1.120546  mean_squared_error     514.881524   \n",
       "5     ExtraTreesMSE_BAG_L2  -1.127092  mean_squared_error     511.873779   \n",
       "6   RandomForestMSE_BAG_L1  -1.151460  mean_squared_error       4.241178   \n",
       "7          CatBoost_BAG_L1  -1.216908  mean_squared_error       1.278060   \n",
       "8        LightGBMXT_BAG_L2  -1.260292  mean_squared_error     511.187376   \n",
       "9        LightGBMXT_BAG_L1  -1.444756  mean_squared_error     321.162151   \n",
       "10         LightGBM_BAG_L1  -1.539981  mean_squared_error     180.046129   \n",
       "11   KNeighborsDist_BAG_L1  -1.580387  mean_squared_error       0.740592   \n",
       "12   KNeighborsUnif_BAG_L1  -1.639574  mean_squared_error       0.885184   \n",
       "13         LightGBM_BAG_L2  -1.887899  mean_squared_error     508.786626   \n",
       "\n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   2070.606627                0.003002           3.060996            3   \n",
       "1   1747.464475                0.746022         313.035524            2   \n",
       "2   1703.245174                3.450133         268.816223            2   \n",
       "3   1053.284036                0.002140           1.786626            2   \n",
       "4   1477.557170                6.528230          43.128219            2   \n",
       "5   1442.565665                3.520484           8.136714            2   \n",
       "6     14.643198                4.241178          14.643198            1   \n",
       "7   1036.116752                1.278060        1036.116752            1   \n",
       "8   1488.593170                2.834081          54.164219            2   \n",
       "9    228.648296              321.162151         228.648296            1   \n",
       "10   153.706756              180.046129         153.706756            1   \n",
       "11     0.737460                0.740592           0.737460            1   \n",
       "12     0.576489                0.885184           0.576489            1   \n",
       "13  1461.103691                0.433331          26.674741            2   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         14  \n",
       "1        True         11  \n",
       "2        True         13  \n",
       "3        True          7  \n",
       "4        True         10  \n",
       "5        True         12  \n",
       "6        True          5  \n",
       "7        True          6  \n",
       "8        True          8  \n",
       "9        True          3  \n",
       "10       True          4  \n",
       "11       True          2  \n",
       "12       True          1  \n",
       "13       True          9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create AutoGluon predictor for regression (use MSE as metric, for example)\n",
    "predictor_baseline = TabularPredictor(\n",
    "    label='Kd',  # or 'Kd' depending on your target transform\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=3600,\n",
    "    presets='best_quality'\n",
    ")\n",
    "\n",
    "predictor_baseline.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03667d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250506_134738\"\n",
      "Verbosity: 2 (Standard Logging)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          12\n",
      "Memory Avail:       1.92 GB / 7.42 GB (25.9%)\n",
      "Disk Space Avail:   14.64 GB / 262.54 GB (5.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_134738\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val         eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L3      -1.120948  -1.133455  mean_squared_error       17.736148      10.848504  870.631655                 0.040743                0.004003           1.524737            3       True          8\n",
      "1      CatBoost_BAG_L2      -1.123877  -1.142710  mean_squared_error       15.433940       6.406062  849.098466                 1.600792                0.285392         255.753094            2       True          7\n",
      "2  WeightedEnsemble_L2      -1.138325  -1.151529  mean_squared_error        8.973116       4.907090  576.511560                 0.155009                0.002024           0.255486            2       True          4\n",
      "3  RandomForest_BAG_L1      -1.154038  -1.176547  mean_squared_error        2.176884       4.052510   13.104742                 2.176884                4.052510          13.104742            1       True          2\n",
      "4  RandomForest_BAG_L2      -1.156029  -1.177661  mean_squared_error       16.094613      10.559109  613.353824                 2.261466                4.438439          20.008452            2       True          6\n",
      "5      CatBoost_BAG_L1      -1.268233  -1.290565  mean_squared_error        6.641224       0.852556  563.151332                 6.641224                0.852556         563.151332            1       True          3\n",
      "6      LightGBM_BAG_L1      -1.376346  -1.502792  mean_squared_error        5.015040       1.215604   17.089298                 5.015040                1.215604          17.089298            1       True          1\n",
      "7      LightGBM_BAG_L2      -1.610625  -1.907859  mean_squared_error       15.334883       6.579073  618.349776                 1.501735                0.458403          25.004404            2       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t1108s\t = DyStack   runtime |\t2492s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2492s\n",
      "AutoGluon will save models to \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_134738\"\n",
      "Train Data Rows:    48873\n",
      "Train Data Columns: 9\n",
      "Label Column:       Kd\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1206.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.36 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\t0.3s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.36 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'FASTAI': [{}],\n",
      "\t'GBM': [{}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'RF': [{}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1660.80s of the 2491.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.41%)\n",
      "\t-1.7954\t = Validation score   (-mean_squared_error)\n",
      "\t131.36s\t = Training   runtime\n",
      "\t160.69s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 1423.71s of the 2254.73s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 92 due to low memory. Expected memory usage reduced from 48.75% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1526\t = Validation score   (-mean_squared_error)\n",
      "\t13.18s\t = Training   runtime\n",
      "\t4.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1404.61s of the 2235.63s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.58% memory usage per fold, 61.16%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=30.58%)\n",
      "\t-1.1977\t = Validation score   (-mean_squared_error)\n",
      "\t1263.83s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 114.26s of the 945.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.40%)\n",
      "\t-1.7039\t = Validation score   (-mean_squared_error)\n",
      "\t155.87s\t = Training   runtime\n",
      "\t3.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 754.00s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForest_BAG_L1': 0.591, 'CatBoost_BAG_L1': 0.409}\n",
      "\t-1.1128\t = Validation score   (-mean_squared_error)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 5 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 752.05s of the 751.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.90%)\n",
      "\t-1.0984\t = Validation score   (-mean_squared_error)\n",
      "\t42.84s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 681.83s of the 681.75s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 144 due to low memory. Expected memory usage reduced from 31.12% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1285\t = Validation score   (-mean_squared_error)\n",
      "\t38.72s\t = Training   runtime\n",
      "\t7.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 633.10s of the 633.02s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.15% memory usage per fold, 46.30%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=23.15%)\n",
      "\t-1.099\t = Validation score   (-mean_squared_error)\n",
      "\t349.77s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 254.38s of the 254.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.24%)\n",
      "\t-1.0987\t = Validation score   (-mean_squared_error)\n",
      "\t256.45s\t = Training   runtime\n",
      "\t3.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -45.33s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.391, 'RandomForest_BAG_L2': 0.261, 'LightGBM_BAG_L2': 0.217, 'CatBoost_BAG_L2': 0.13}\n",
      "\t-1.09\t = Validation score   (-mean_squared_error)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2540.25s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 35.6 rows/s (6110 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_134738\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model  score_val         eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3  -1.089994  mean_squared_error     181.899813  2254.122085                0.023304           2.096485            3       True         10\n",
      "1         LightGBM_BAG_L2  -1.098402  mean_squared_error     170.312796  1607.085340                0.479897          42.837988            2       True          6\n",
      "2  NeuralNetFastAI_BAG_L2  -1.098679  mean_squared_error     173.645092  1820.699138                3.812193         256.451786            2       True          9\n",
      "3         CatBoost_BAG_L2  -1.099015  mean_squared_error     170.214036  1914.015124                0.381137         349.767773            2       True          8\n",
      "4     WeightedEnsemble_L2  -1.112834  mean_squared_error       5.579888  1278.664041                0.007324           1.648161            2       True          5\n",
      "5     RandomForest_BAG_L2  -1.128507  mean_squared_error     177.203282  1602.968053                7.370383          38.720701            2       True          7\n",
      "6     RandomForest_BAG_L1  -1.152557  mean_squared_error       4.218316    13.181410                4.218316          13.181410            1       True          2\n",
      "7         CatBoost_BAG_L1  -1.197710  mean_squared_error       1.354248  1263.834470                1.354248        1263.834470            1       True          3\n",
      "8  NeuralNetFastAI_BAG_L1  -1.703904  mean_squared_error       3.568819   155.873268                3.568819         155.873268            1       True          4\n",
      "9         LightGBM_BAG_L1  -1.795384  mean_squared_error     160.691516   131.358204              160.691516         131.358204            1       True          1\n",
      "Number of models trained: 10\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_RF', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_BAG_L2': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBM_BAG_L1': -1.7953837250423779,\n",
       "  'RandomForest_BAG_L1': -1.1525568446670469,\n",
       "  'CatBoost_BAG_L1': -1.1977104409506025,\n",
       "  'NeuralNetFastAI_BAG_L1': -1.703904400676673,\n",
       "  'WeightedEnsemble_L2': -1.112833884915612,\n",
       "  'LightGBM_BAG_L2': -1.0984022457410685,\n",
       "  'RandomForest_BAG_L2': -1.128506813488998,\n",
       "  'CatBoost_BAG_L2': -1.099014898348514,\n",
       "  'NeuralNetFastAI_BAG_L2': -1.0986792784833732,\n",
       "  'WeightedEnsemble_L3': -1.089993884748694},\n",
       " 'model_best': 'WeightedEnsemble_L3',\n",
       " 'model_paths': {'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'RandomForest_BAG_L1': ['RandomForest_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'RandomForest_BAG_L2': ['RandomForest_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'NeuralNetFastAI_BAG_L2': ['NeuralNetFastAI_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'LightGBM_BAG_L1': 131.35820412635803,\n",
       "  'RandomForest_BAG_L1': 13.18140959739685,\n",
       "  'CatBoost_BAG_L1': 1263.834469795227,\n",
       "  'NeuralNetFastAI_BAG_L1': 155.8732681274414,\n",
       "  'WeightedEnsemble_L2': 1.6481611728668213,\n",
       "  'LightGBM_BAG_L2': 42.83798813819885,\n",
       "  'RandomForest_BAG_L2': 38.72070097923279,\n",
       "  'CatBoost_BAG_L2': 349.76777267456055,\n",
       "  'NeuralNetFastAI_BAG_L2': 256.45178627967834,\n",
       "  'WeightedEnsemble_L3': 2.0964853763580322},\n",
       " 'model_pred_times': {'LightGBM_BAG_L1': 160.6915156841278,\n",
       "  'RandomForest_BAG_L1': 4.218316078186035,\n",
       "  'CatBoost_BAG_L1': 1.354247808456421,\n",
       "  'NeuralNetFastAI_BAG_L1': 3.568819284439087,\n",
       "  'WeightedEnsemble_L2': 0.0073244571685791016,\n",
       "  'LightGBM_BAG_L2': 0.47989749908447266,\n",
       "  'RandomForest_BAG_L2': 7.370383262634277,\n",
       "  'CatBoost_BAG_L2': 0.3811368942260742,\n",
       "  'NeuralNetFastAI_BAG_L2': 3.8121931552886963,\n",
       "  'WeightedEnsemble_L3': 0.023303508758544922},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'model_hyperparams': {'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'RandomForest_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'RandomForest_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None}},\n",
       " 'leaderboard':                     model  score_val         eval_metric  pred_time_val  \\\n",
       " 0     WeightedEnsemble_L3  -1.089994  mean_squared_error     181.899813   \n",
       " 1         LightGBM_BAG_L2  -1.098402  mean_squared_error     170.312796   \n",
       " 2  NeuralNetFastAI_BAG_L2  -1.098679  mean_squared_error     173.645092   \n",
       " 3         CatBoost_BAG_L2  -1.099015  mean_squared_error     170.214036   \n",
       " 4     WeightedEnsemble_L2  -1.112834  mean_squared_error       5.579888   \n",
       " 5     RandomForest_BAG_L2  -1.128507  mean_squared_error     177.203282   \n",
       " 6     RandomForest_BAG_L1  -1.152557  mean_squared_error       4.218316   \n",
       " 7         CatBoost_BAG_L1  -1.197710  mean_squared_error       1.354248   \n",
       " 8  NeuralNetFastAI_BAG_L1  -1.703904  mean_squared_error       3.568819   \n",
       " 9         LightGBM_BAG_L1  -1.795384  mean_squared_error     160.691516   \n",
       " \n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0  2254.122085                0.023304           2.096485            3   \n",
       " 1  1607.085340                0.479897          42.837988            2   \n",
       " 2  1820.699138                3.812193         256.451786            2   \n",
       " 3  1914.015124                0.381137         349.767773            2   \n",
       " 4  1278.664041                0.007324           1.648161            2   \n",
       " 5  1602.968053                7.370383          38.720701            2   \n",
       " 6    13.181410                4.218316          13.181410            1   \n",
       " 7  1263.834470                1.354248        1263.834470            1   \n",
       " 8   155.873268                3.568819         155.873268            1   \n",
       " 9   131.358204              160.691516         131.358204            1   \n",
       " \n",
       "    can_infer  fit_order  \n",
       " 0       True         10  \n",
       " 1       True          6  \n",
       " 2       True          9  \n",
       " 3       True          8  \n",
       " 4       True          5  \n",
       " 5       True          7  \n",
       " 6       True          2  \n",
       " 7       True          3  \n",
       " 8       True          4  \n",
       " 9       True          1  }"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_hyperparams = {\n",
    "    'FASTAI': {},\n",
    "    'GBM': {},        # Covers LightGBMLarge, LightGBMXT, etc.\n",
    "    'CAT': {},\n",
    "    'XGB': {},        # In case XGBoost is considered\n",
    "    'RF': {}          # Random Forests as a backup\n",
    "}\n",
    "\n",
    "predictor_tuned = TabularPredictor(\n",
    "    label='Kd', \n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters=custom_hyperparams,\n",
    "    time_limit=3600,  # adjust based on compute\n",
    "    presets='best_quality'\n",
    ")\n",
    "\n",
    "predictor_tuned.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a189b841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-1.089994</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>181.899813</td>\n",
       "      <td>2254.122085</td>\n",
       "      <td>0.023304</td>\n",
       "      <td>2.096485</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-1.098402</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>170.312796</td>\n",
       "      <td>1607.085340</td>\n",
       "      <td>0.479897</td>\n",
       "      <td>42.837988</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-1.098679</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>173.645092</td>\n",
       "      <td>1820.699138</td>\n",
       "      <td>3.812193</td>\n",
       "      <td>256.451786</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-1.099015</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>170.214036</td>\n",
       "      <td>1914.015124</td>\n",
       "      <td>0.381137</td>\n",
       "      <td>349.767773</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.112834</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5.579888</td>\n",
       "      <td>1278.664041</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>1.648161</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest_BAG_L2</td>\n",
       "      <td>-1.128507</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>177.203282</td>\n",
       "      <td>1602.968053</td>\n",
       "      <td>7.370383</td>\n",
       "      <td>38.720701</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest_BAG_L1</td>\n",
       "      <td>-1.152557</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>4.218316</td>\n",
       "      <td>13.181410</td>\n",
       "      <td>4.218316</td>\n",
       "      <td>13.181410</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-1.197710</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.354248</td>\n",
       "      <td>1263.834470</td>\n",
       "      <td>1.354248</td>\n",
       "      <td>1263.834470</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-1.703904</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>3.568819</td>\n",
       "      <td>155.873268</td>\n",
       "      <td>3.568819</td>\n",
       "      <td>155.873268</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-1.795384</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>160.691516</td>\n",
       "      <td>131.358204</td>\n",
       "      <td>160.691516</td>\n",
       "      <td>131.358204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val         eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L3  -1.089994  mean_squared_error     181.899813   \n",
       "1         LightGBM_BAG_L2  -1.098402  mean_squared_error     170.312796   \n",
       "2  NeuralNetFastAI_BAG_L2  -1.098679  mean_squared_error     173.645092   \n",
       "3         CatBoost_BAG_L2  -1.099015  mean_squared_error     170.214036   \n",
       "4     WeightedEnsemble_L2  -1.112834  mean_squared_error       5.579888   \n",
       "5     RandomForest_BAG_L2  -1.128507  mean_squared_error     177.203282   \n",
       "6     RandomForest_BAG_L1  -1.152557  mean_squared_error       4.218316   \n",
       "7         CatBoost_BAG_L1  -1.197710  mean_squared_error       1.354248   \n",
       "8  NeuralNetFastAI_BAG_L1  -1.703904  mean_squared_error       3.568819   \n",
       "9         LightGBM_BAG_L1  -1.795384  mean_squared_error     160.691516   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  2254.122085                0.023304           2.096485            3   \n",
       "1  1607.085340                0.479897          42.837988            2   \n",
       "2  1820.699138                3.812193         256.451786            2   \n",
       "3  1914.015124                0.381137         349.767773            2   \n",
       "4  1278.664041                0.007324           1.648161            2   \n",
       "5  1602.968053                7.370383          38.720701            2   \n",
       "6    13.181410                4.218316          13.181410            1   \n",
       "7  1263.834470                1.354248        1263.834470            1   \n",
       "8   155.873268                3.568819         155.873268            1   \n",
       "9   131.358204              160.691516         131.358204            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         10  \n",
       "1       True          6  \n",
       "2       True          9  \n",
       "3       True          8  \n",
       "4       True          5  \n",
       "5       True          7  \n",
       "6       True          2  \n",
       "7       True          3  \n",
       "8       True          4  \n",
       "9       True          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tuned.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbb1969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250506_144828\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          12\n",
      "Memory Avail:       1.47 GB / 7.42 GB (19.8%)\n",
      "Disk Space Avail:   14.05 GB / 262.54 GB (5.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 7200s\n",
      "AutoGluon will save models to \"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_144828\"\n",
      "Train Data Rows:    48873\n",
      "Train Data Columns: 9\n",
      "Label Column:       Kd\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1489.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['MolWt', 'LogP', 'Prot_MW', 'Aromaticity', 'Instability', ...]\n",
      "\t\t('int', [])   : 3 | ['RotatableBonds', 'HDonors', 'HAcceptors']\n",
      "\t0.5s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.36 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.71s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'FASTAI': [{}],\n",
      "\t'GBM': [{}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'RF': [{}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3198.88s of the 7199.27s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=1.95%)\n",
      "\t-1.1739\t = Validation score   (-mean_squared_error)\n",
      "\t306.07s\t = Training   runtime\n",
      "\t110.97s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 2833.28s of the 6833.67s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 101 due to low memory. Expected memory usage reduced from 44.38% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1501\t = Validation score   (-mean_squared_error)\n",
      "\t13.55s\t = Training   runtime\n",
      "\t4.87s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2812.58s of the 6812.97s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.23% memory usage per fold, 56.47%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=28.23%)\n",
      "\t-1.1777\t = Validation score   (-mean_squared_error)\n",
      "\t2347.94s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 436.75s of the 4437.14s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.47%)\n",
      "\t-1.6466\t = Validation score   (-mean_squared_error)\n",
      "\t379.78s\t = Training   runtime\n",
      "\t3.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 15.54s of the 4015.93s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=2.81%)\n",
      "\t-1.3342\t = Validation score   (-mean_squared_error)\n",
      "\t50.4s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3947.59s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForest_BAG_L1': 0.52, 'LightGBM_BAG_L1': 0.24, 'CatBoost_BAG_L1': 0.24}\n",
      "\t-1.1008\t = Validation score   (-mean_squared_error)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 5 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2630.04s of the 3945.99s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=3.08%)\n",
      "\t-1.094\t = Validation score   (-mean_squared_error)\n",
      "\t31.99s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 2566.85s of the 3882.80s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 104 due to low memory. Expected memory usage reduced from 43.21% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1203\t = Validation score   (-mean_squared_error)\n",
      "\t35.81s\t = Training   runtime\n",
      "\t4.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2523.97s of the 3839.92s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.26% memory usage per fold, 58.53%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=29.26%)\n",
      "\t-1.0936\t = Validation score   (-mean_squared_error)\n",
      "\t222.47s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 2275.09s of the 3591.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.52%)\n",
      "\t-1.0935\t = Validation score   (-mean_squared_error)\n",
      "\t662.42s\t = Training   runtime\n",
      "\t4.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1564.44s of the 2880.39s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=3.35%)\n",
      "\t-1.0943\t = Validation score   (-mean_squared_error)\n",
      "\t36.22s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2823.04s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.36, 'RandomForest_BAG_L2': 0.28, 'XGBoost_BAG_L2': 0.2, 'CatBoost_BAG_L2': 0.16}\n",
      "\t-1.0832\t = Validation score   (-mean_squared_error)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 5 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 2821.51s of the 2821.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=2.89%)\n",
      "\t-1.089\t = Validation score   (-mean_squared_error)\n",
      "\t27.16s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L3 ... Training model for up to 2768.21s of the 2768.04s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 97 due to low memory. Expected memory usage reduced from 46.05% -> 15.0% of available memory...\n",
      "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-1.1371\t = Validation score   (-mean_squared_error)\n",
      "\t37.71s\t = Training   runtime\n",
      "\t5.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 2723.43s of the 2723.26s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 33.97% memory usage per fold, 67.93%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=33.97%)\n",
      "\t-1.0863\t = Validation score   (-mean_squared_error)\n",
      "\t143.83s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 2552.09s of the 2551.92s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=4.80%)\n",
      "\t-1.0837\t = Validation score   (-mean_squared_error)\n",
      "\t691.18s\t = Training   runtime\n",
      "\t3.87s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 1818.47s of the 1818.30s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.09%)\n",
      "\t-1.7756\t = Validation score   (-mean_squared_error)\n",
      "\t40.1s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 359.98s of the 1757.61s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L3': 0.36, 'NeuralNetFastAI_BAG_L2': 0.16, 'RandomForest_BAG_L2': 0.12, 'RandomForest_BAG_L3': 0.12, 'CatBoost_BAG_L2': 0.08, 'XGBoost_BAG_L2': 0.08, 'LightGBM_BAG_L3': 0.04, 'CatBoost_BAG_L3': 0.04}\n",
      "\t-1.0817\t = Validation score   (-mean_squared_error)\n",
      "\t3.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5445.74s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 75.4 rows/s (9775 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\NongNam\\Documents\\AI_Builder\\MODEL\\AutoGluon\\AutogluonModels\\ag-20250506_144828\")\n"
     ]
    }
   ],
   "source": [
    "predictor_ensemble = TabularPredictor(\n",
    "    label='Kd',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_squared_error'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters=custom_hyperparams,\n",
    "    num_bag_folds=5,\n",
    "    num_stack_levels=2,\n",
    "    time_limit=7200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11a09cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-1.089994</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>181.899813</td>\n",
       "      <td>2254.122085</td>\n",
       "      <td>0.023304</td>\n",
       "      <td>2.096485</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-1.098402</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>170.312796</td>\n",
       "      <td>1607.085340</td>\n",
       "      <td>0.479897</td>\n",
       "      <td>42.837988</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-1.098679</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>173.645092</td>\n",
       "      <td>1820.699138</td>\n",
       "      <td>3.812193</td>\n",
       "      <td>256.451786</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-1.099015</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>170.214036</td>\n",
       "      <td>1914.015124</td>\n",
       "      <td>0.381137</td>\n",
       "      <td>349.767773</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.112834</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5.579888</td>\n",
       "      <td>1278.664041</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>1.648161</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest_BAG_L2</td>\n",
       "      <td>-1.128507</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>177.203282</td>\n",
       "      <td>1602.968053</td>\n",
       "      <td>7.370383</td>\n",
       "      <td>38.720701</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest_BAG_L1</td>\n",
       "      <td>-1.152557</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>4.218316</td>\n",
       "      <td>13.181410</td>\n",
       "      <td>4.218316</td>\n",
       "      <td>13.181410</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-1.197710</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.354248</td>\n",
       "      <td>1263.834470</td>\n",
       "      <td>1.354248</td>\n",
       "      <td>1263.834470</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-1.703904</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>3.568819</td>\n",
       "      <td>155.873268</td>\n",
       "      <td>3.568819</td>\n",
       "      <td>155.873268</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-1.795384</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>160.691516</td>\n",
       "      <td>131.358204</td>\n",
       "      <td>160.691516</td>\n",
       "      <td>131.358204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val         eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L3  -1.089994  mean_squared_error     181.899813   \n",
       "1         LightGBM_BAG_L2  -1.098402  mean_squared_error     170.312796   \n",
       "2  NeuralNetFastAI_BAG_L2  -1.098679  mean_squared_error     173.645092   \n",
       "3         CatBoost_BAG_L2  -1.099015  mean_squared_error     170.214036   \n",
       "4     WeightedEnsemble_L2  -1.112834  mean_squared_error       5.579888   \n",
       "5     RandomForest_BAG_L2  -1.128507  mean_squared_error     177.203282   \n",
       "6     RandomForest_BAG_L1  -1.152557  mean_squared_error       4.218316   \n",
       "7         CatBoost_BAG_L1  -1.197710  mean_squared_error       1.354248   \n",
       "8  NeuralNetFastAI_BAG_L1  -1.703904  mean_squared_error       3.568819   \n",
       "9         LightGBM_BAG_L1  -1.795384  mean_squared_error     160.691516   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  2254.122085                0.023304           2.096485            3   \n",
       "1  1607.085340                0.479897          42.837988            2   \n",
       "2  1820.699138                3.812193         256.451786            2   \n",
       "3  1914.015124                0.381137         349.767773            2   \n",
       "4  1278.664041                0.007324           1.648161            2   \n",
       "5  1602.968053                7.370383          38.720701            2   \n",
       "6    13.181410                4.218316          13.181410            1   \n",
       "7  1263.834470                1.354248        1263.834470            1   \n",
       "8   155.873268                3.568819         155.873268            1   \n",
       "9   131.358204              160.691516         131.358204            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         10  \n",
       "1       True          6  \n",
       "2       True          9  \n",
       "3       True          8  \n",
       "4       True          5  \n",
       "5       True          7  \n",
       "6       True          2  \n",
       "7       True          3  \n",
       "8       True          4  \n",
       "9       True          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tuned.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c467a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_tuned.save(\"autogluon_kd_predictor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
