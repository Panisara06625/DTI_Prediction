{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: jupyterlab in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (4.4.1)\n",
            "Requirement already satisfied: torch in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2.6.0)\n",
            "Requirement already satisfied: torch-geometric in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: rdkit in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (2024.9.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (6.29.5)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (6.4.2)\n",
            "Requirement already satisfied: traitlets in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab) (5.14.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch-geometric) (3.11.18)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.16.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.14)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (9.2.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.3)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=24 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (26.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-core->jupyterlab) (4.3.7)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-core->jupyterlab) (310)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
            "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (2.0.15)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
            "Requirement already satisfied: rich in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.24.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.4)\n",
            "Requirement already satisfied: bleach[css]!=5.0.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: fqdn in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: isoduration in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: uri-template in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.7)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
            "Requirement already satisfied: pycparser in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\nongnam\\documents\\ai_builder\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.9.0.20241206)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn tensorflow matplotlib seaborn jupyterlab torch torch-geometric rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oWSzPzgfI-Ro"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# === Core Libraries ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import glob\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "\n",
        "# === RDKit for Molecular Processing ===\n",
        "from rdkit import Chem\n",
        "\n",
        "# === PyTorch & PyTorch Geometric ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, NNConv, global_mean_pool\n",
        "\n",
        "# === TensorFlow / Keras ===\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Conv1D, GlobalMaxPooling1D,\n",
        "    BatchNormalization, Dropout, Dense, Concatenate, Add, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# === Scikit-learn ===\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "zbLxZIAghLDq",
        "outputId": "ecad2237-2429-4f1c-e1a2-3548ebe223d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>target_sequence</th>\n",
              "      <th>Kd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COc1cc2nc(cnc2cc1OCC#N)-c1ccc(CC(=O)Nc2cc(on2)...</td>\n",
              "      <td>MPALARDGGQLPLLVVFSAMIFGTITNQDLPVIKCVLINHKNNDSS...</td>\n",
              "      <td>8.301030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cn1nc(C(=O)NC[C@@]2(O)CC[C@@H](CC2)S(C)(=O)=O)...</td>\n",
              "      <td>MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...</td>\n",
              "      <td>7.795880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oc1ccc(/C=C/c2cc(O)cc(O)c2)cc1</td>\n",
              "      <td>MDDIYKAAVEQLTEEQKNEFKAAFDIFVLGAEDGCISTKELGKVMR...</td>\n",
              "      <td>3.614394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cc1ccc(CNc2nc3c(N)ncnc3n2[C@@H]2O[C@H](CO)[C@@...</td>\n",
              "      <td>MSKGPAVGIDLGTTYSCVGVFQHGKVEIIANDQGNRTTPSYVAFTD...</td>\n",
              "      <td>6.530178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC\\C=C\\CCOC(=O)c1cccnc1</td>\n",
              "      <td>MSALGVTVALLVWAAFLLLVSMWRQVHSSWNLPPGPFPLPIIGNLF...</td>\n",
              "      <td>5.886057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              SMILES  \\\n",
              "0  COc1cc2nc(cnc2cc1OCC#N)-c1ccc(CC(=O)Nc2cc(on2)...   \n",
              "1  Cn1nc(C(=O)NC[C@@]2(O)CC[C@@H](CC2)S(C)(=O)=O)...   \n",
              "2                     Oc1ccc(/C=C/c2cc(O)cc(O)c2)cc1   \n",
              "3  Cc1ccc(CNc2nc3c(N)ncnc3n2[C@@H]2O[C@H](CO)[C@@...   \n",
              "4                            CC\\C=C\\CCOC(=O)c1cccnc1   \n",
              "\n",
              "                                     target_sequence        Kd  \n",
              "0  MPALARDGGQLPLLVVFSAMIFGTITNQDLPVIKCVLINHKNNDSS...  8.301030  \n",
              "1  MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...  7.795880  \n",
              "2  MDDIYKAAVEQLTEEQKNEFKAAFDIFVLGAEDGCISTKELGKVMR...  3.614394  \n",
              "3  MSKGPAVGIDLGTTYSCVGVFQHGKVEIIANDQGNRTTPSYVAFTD...  6.530178  \n",
              "4  MSALGVTVALLVWAAFLLLVSMWRQVHSSWNLPPGPFPLPIIGNLF...  5.886057  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Load data ===\n",
        "df = pd.read_csv(\"Kd.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "8CFafgX2iJBw",
        "outputId": "8fd9e798-95a5-4f76-b2d0-31bc9d6ef6a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SMILES             0\n",
              "target_sequence    0\n",
              "Kd                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAl2Ls55wSik",
        "outputId": "ef845a06-bf3e-402a-9060-cec655a80a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55011"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x_cMJtBF7rc3"
      },
      "outputs": [],
      "source": [
        "# Encode amino acid sequences\n",
        "aa_list = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "aa_to_int = {aa: i + 1 for i, aa in enumerate(aa_list)}\n",
        "\n",
        "def encode_protein(seq):\n",
        "    return [aa_to_int.get(aa, 0) for aa in seq]\n",
        "\n",
        "df['protein_encoded'] = df['target_sequence'].apply(encode_protein)\n",
        "\n",
        "# Pad protein sequences\n",
        "max_len_protein = 1000\n",
        "X_protein = pad_sequences(df['protein_encoded'], maxlen=max_len_protein, padding='post')\n",
        "\n",
        "# Store Kd values\n",
        "y_kd = df['Kd'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_atom_features(atom):\n",
        "    return [\n",
        "        atom.GetAtomicNum(),\n",
        "        atom.GetDegree(),\n",
        "        atom.GetFormalCharge(),\n",
        "        int(atom.GetHybridization()),\n",
        "        int(atom.GetIsAromatic())\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bond_features(bond):\n",
        "    return [\n",
        "        int(bond.GetBondTypeAsDouble()),   # Single=1.0, Double=2.0, etc.\n",
        "        int(bond.GetIsConjugated()),\n",
        "        int(bond.GetIsAromatic())\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uws0C2grFKsr",
        "outputId": "7435fe0a-8888-4e13-aba8-da69fd9f43b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[18:34:46] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
            "[18:34:51] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
            "[18:34:57] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
            "[18:35:07] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
            "[18:35:29] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
            "[18:35:41] Can't kekulize mol.  Unkekulized atoms: 16 17 18 19 20 21 22 23 25\n",
            "[18:35:50] Explicit valence for atom # 22 N, 4, is greater than permitted\n"
          ]
        }
      ],
      "source": [
        "def smiles_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    smiles = Chem.MolToSmiles(mol)\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    x = torch.tensor([get_atom_features(atom) for atom in mol.GetAtoms()], dtype=torch.float)\n",
        "\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "\n",
        "    for bond in mol.GetBonds():\n",
        "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        edge_index += [[i, j], [j, i]]\n",
        "        bond_feat = get_bond_features(bond)\n",
        "        edge_attr += [bond_feat, bond_feat]  # Add both directions\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# Apply and filter out None values (only valid SMILES)\n",
        "graph_data_list = []\n",
        "valid_indices = []\n",
        "\n",
        "for i, smiles in enumerate(df['SMILES']):\n",
        "    graph = smiles_to_graph(smiles)\n",
        "    if graph is not None:\n",
        "        graph_data_list.append(graph)\n",
        "        valid_indices.append(i)\n",
        "\n",
        "# Filter protein and Kd tensors to match valid molecules\n",
        "X_protein = X_protein[valid_indices]\n",
        "y_kd = y_kd[valid_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[39, 5], edge_index=[2, 86], edge_attr=[86, 3])\n"
          ]
        }
      ],
      "source": [
        "print(graph_data_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bjsQ_rgFD6OL"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(nn.Module):\n",
        "    def __init__(self, node_in=5, edge_in=3):\n",
        "        super().__init__()\n",
        "        self.edge_nn1 = nn.Sequential(\n",
        "            nn.Linear(edge_in, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, node_in * 64)\n",
        "        )\n",
        "        self.conv1 = NNConv(node_in, 64, self.edge_nn1, aggr='mean')\n",
        "\n",
        "        self.edge_nn2 = nn.Sequential(\n",
        "            nn.Linear(edge_in, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64 * 128)\n",
        "        )\n",
        "        self.conv2 = NNConv(64, 128, self.edge_nn2, aggr='mean')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x = torch.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = torch.relu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6y5pi6_9I3oK",
        "outputId": "86e42c4b-ed88-4cf8-c1b2-7d06df1702d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ protein_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │ protein_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ protein_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m1,344\u001b[0m │ protein_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m73,856\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m41,088\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m384\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">595,649</span> (2.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m595,649\u001b[0m (2.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">594,113</span> (2.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m594,113\u001b[0m (2.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Protein CNN Branch ---\n",
        "protein_input = Input(shape=(max_len_protein,), name=\"protein_input\")\n",
        "x = Embedding(input_dim=len(aa_to_int) + 1, output_dim=64)(protein_input)\n",
        "x1 = Conv1D(128, kernel_size=9, activation='relu', padding='same')(x)\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Conv1D(256, kernel_size=9, activation='relu', padding='same')(x1)\n",
        "x1 = BatchNormalization()(x1)\n",
        "\n",
        "x2 = Conv1D(128, kernel_size=5, activation='relu', padding='same')(x)\n",
        "x2 = BatchNormalization()(x2)\n",
        "\n",
        "# Skip connection via concatenation\n",
        "merged_cnn = Concatenate()([x1, x2])\n",
        "x_cnn = GlobalMaxPooling1D()(merged_cnn)\n",
        "x_cnn = Dropout(0.4)(x_cnn)\n",
        "\n",
        "# --- GNN Features Input ---\n",
        "gnn_input = Input(shape=(128,), name=\"gnn_input\")\n",
        "\n",
        "# Optional layer norm or transformation layer\n",
        "gnn_proj = Dense(128, activation='relu')(gnn_input)\n",
        "gnn_proj = LayerNormalization()(gnn_proj)\n",
        "\n",
        "# --- Merge branches ---\n",
        "merged = Concatenate()([x_cnn, gnn_proj])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dense(256, activation='relu')(merged)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# x = Dropout(0.2)(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='linear')(x)\n",
        "\n",
        "model = Model(inputs=[protein_input, gnn_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['mae'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EpochHistorySaver(Callback):\n",
        "    def __init__(self, save_dir='GNN_MODEL'):\n",
        "        super().__init__()\n",
        "        self.save_dir = save_dir\n",
        "        self.history = {}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        for key, value in logs.items():\n",
        "            self.history.setdefault(key, []).append(value)\n",
        "\n",
        "        # Save history after each epoch\n",
        "        filename = f'{self.save_dir}/history_epoch_{epoch+1:02d}.pkl'\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self.history, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y38LAo1A3gyx"
      },
      "outputs": [],
      "source": [
        "# Save the model at every epoch with the epoch number in the filename\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath='GNN_MODEL/model_epoch_{epoch:02d}.h5',\n",
        "    save_freq='epoch',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history_cb = EpochHistorySaver(save_dir='GNN_MODEL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataLoader for batching the graph data\n",
        "batch_size = 32  # You can experiment with this size depending on your memory capacity\n",
        "\n",
        "loader = DataLoader(graph_data_list, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting GNN Features: 100%|██████████| 1719/1719 [03:39<00:00,  7.83it/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the GNN encoder model\n",
        "gnn_model = GNNEncoder()\n",
        "gnn_model.eval()\n",
        "gnn_model.cpu()  # Use CPU if GPU memory is limited\n",
        "\n",
        "# List to store the GNN features\n",
        "gnn_features_list = []\n",
        "\n",
        "# Iterate over the DataLoader with tqdm for progress tracking\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(loader, desc=\"Extracting GNN Features\"):\n",
        "        gnn_features = gnn_model(batch)  # Forward pass through the GNN\n",
        "        gnn_features_list.append(gnn_features.cpu().numpy())  # Store the features\n",
        "\n",
        "# Concatenate all the features\n",
        "gnn_features = np.concatenate(gnn_features_list, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# model = load_model('GNN_MODEL/model_epoch_52.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHyP9h5pI5PG",
        "outputId": "0a9fd67f-61e0-46ad-da88-7c0b407ae214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 6.8435 - mae: 1.9776\n",
            "Epoch 1: saving model to GNN_MODEL/model_epoch_01.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1452s\u001b[0m 2s/step - loss: 6.8398 - mae: 1.9770 - val_loss: 7.8804 - val_mae: 2.3939\n",
            "Epoch 2/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.6622 - mae: 1.2631\n",
            "Epoch 2: saving model to GNN_MODEL/model_epoch_02.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1391s\u001b[0m 2s/step - loss: 2.6620 - mae: 1.2631 - val_loss: 5.1337 - val_mae: 1.9252\n",
            "Epoch 3/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.2719 - mae: 1.1483\n",
            "Epoch 3: saving model to GNN_MODEL/model_epoch_03.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1464s\u001b[0m 2s/step - loss: 2.2718 - mae: 1.1482 - val_loss: 3.0808 - val_mae: 1.3575\n",
            "Epoch 4/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.1302 - mae: 1.1114\n",
            "Epoch 4: saving model to GNN_MODEL/model_epoch_04.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1397s\u001b[0m 2s/step - loss: 2.1302 - mae: 1.1114 - val_loss: 2.8568 - val_mae: 1.2940\n",
            "Epoch 5/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.0259 - mae: 1.0764\n",
            "Epoch 5: saving model to GNN_MODEL/model_epoch_05.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1496s\u001b[0m 2s/step - loss: 2.0259 - mae: 1.0764 - val_loss: 3.7630 - val_mae: 1.5870\n",
            "Epoch 6/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.9501 - mae: 1.0527\n",
            "Epoch 6: saving model to GNN_MODEL/model_epoch_06.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1380s\u001b[0m 2s/step - loss: 1.9501 - mae: 1.0527 - val_loss: 2.4473 - val_mae: 1.1591\n",
            "Epoch 7/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.9044 - mae: 1.0400\n",
            "Epoch 7: saving model to GNN_MODEL/model_epoch_07.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1323s\u001b[0m 2s/step - loss: 1.9043 - mae: 1.0400 - val_loss: 1.9143 - val_mae: 0.9792\n",
            "Epoch 8/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.8318 - mae: 1.0193\n",
            "Epoch 8: saving model to GNN_MODEL/model_epoch_08.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1399s\u001b[0m 2s/step - loss: 1.8318 - mae: 1.0193 - val_loss: 1.6358 - val_mae: 0.9298\n",
            "Epoch 9/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.8184 - mae: 1.0144\n",
            "Epoch 9: saving model to GNN_MODEL/model_epoch_09.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1301s\u001b[0m 2s/step - loss: 1.8184 - mae: 1.0144 - val_loss: 1.8691 - val_mae: 0.9547\n",
            "Epoch 10/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 1.7848 - mae: 1.0015\n",
            "Epoch 10: saving model to GNN_MODEL/model_epoch_10.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 2s/step - loss: 1.7848 - mae: 1.0015 - val_loss: 1.6816 - val_mae: 0.9093\n",
            "Epoch 11/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 1.7377 - mae: 0.9820\n",
            "Epoch 11: saving model to GNN_MODEL/model_epoch_11.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1090s\u001b[0m 2s/step - loss: 1.7377 - mae: 0.9820 - val_loss: 2.0630 - val_mae: 1.0265\n",
            "Epoch 12/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 1.7101 - mae: 0.9789\n",
            "Epoch 12: saving model to GNN_MODEL/model_epoch_12.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 2s/step - loss: 1.7101 - mae: 0.9789 - val_loss: 1.5950 - val_mae: 0.9133\n",
            "Epoch 13/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.6821 - mae: 0.9730\n",
            "Epoch 13: saving model to GNN_MODEL/model_epoch_13.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 2s/step - loss: 1.6821 - mae: 0.9730 - val_loss: 1.9561 - val_mae: 0.9790\n",
            "Epoch 14/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.6622 - mae: 0.9607\n",
            "Epoch 14: saving model to GNN_MODEL/model_epoch_14.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 2s/step - loss: 1.6622 - mae: 0.9607 - val_loss: 1.5325 - val_mae: 0.8887\n",
            "Epoch 15/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.6118 - mae: 0.9483\n",
            "Epoch 15: saving model to GNN_MODEL/model_epoch_15.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1197s\u001b[0m 2s/step - loss: 1.6118 - mae: 0.9483 - val_loss: 1.9015 - val_mae: 0.9630\n",
            "Epoch 16/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.6208 - mae: 0.9471\n",
            "Epoch 16: saving model to GNN_MODEL/model_epoch_16.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 2s/step - loss: 1.6208 - mae: 0.9471 - val_loss: 1.4490 - val_mae: 0.8691\n",
            "Epoch 17/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5451 - mae: 0.9264\n",
            "Epoch 17: saving model to GNN_MODEL/model_epoch_17.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1194s\u001b[0m 2s/step - loss: 1.5452 - mae: 0.9264 - val_loss: 1.5361 - val_mae: 0.8711\n",
            "Epoch 18/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5693 - mae: 0.9298\n",
            "Epoch 18: saving model to GNN_MODEL/model_epoch_18.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1209s\u001b[0m 2s/step - loss: 1.5692 - mae: 0.9298 - val_loss: 1.4468 - val_mae: 0.9026\n",
            "Epoch 19/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5274 - mae: 0.9198\n",
            "Epoch 19: saving model to GNN_MODEL/model_epoch_19.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1181s\u001b[0m 2s/step - loss: 1.5274 - mae: 0.9198 - val_loss: 1.4627 - val_mae: 0.8873\n",
            "Epoch 20/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5618 - mae: 0.9294\n",
            "Epoch 20: saving model to GNN_MODEL/model_epoch_20.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 2s/step - loss: 1.5618 - mae: 0.9294 - val_loss: 1.5122 - val_mae: 0.8550\n",
            "Epoch 21/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5053 - mae: 0.9076\n",
            "Epoch 21: saving model to GNN_MODEL/model_epoch_21.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 2s/step - loss: 1.5053 - mae: 0.9076 - val_loss: 1.5176 - val_mae: 0.8547\n",
            "Epoch 22/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5375 - mae: 0.9210\n",
            "Epoch 22: saving model to GNN_MODEL/model_epoch_22.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1171s\u001b[0m 2s/step - loss: 1.5375 - mae: 0.9210 - val_loss: 1.4412 - val_mae: 0.8967\n",
            "Epoch 23/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.5035 - mae: 0.9118\n",
            "Epoch 23: saving model to GNN_MODEL/model_epoch_23.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1161s\u001b[0m 2s/step - loss: 1.5035 - mae: 0.9118 - val_loss: 1.4414 - val_mae: 0.8763\n",
            "Epoch 24/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4695 - mae: 0.8983\n",
            "Epoch 24: saving model to GNN_MODEL/model_epoch_24.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1199s\u001b[0m 2s/step - loss: 1.4695 - mae: 0.8983 - val_loss: 1.4571 - val_mae: 0.8427\n",
            "Epoch 25/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4698 - mae: 0.8976\n",
            "Epoch 25: saving model to GNN_MODEL/model_epoch_25.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1216s\u001b[0m 2s/step - loss: 1.4698 - mae: 0.8976 - val_loss: 1.4484 - val_mae: 0.8819\n",
            "Epoch 26/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4521 - mae: 0.8936\n",
            "Epoch 26: saving model to GNN_MODEL/model_epoch_26.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1241s\u001b[0m 2s/step - loss: 1.4521 - mae: 0.8936 - val_loss: 1.4235 - val_mae: 0.8743\n",
            "Epoch 27/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4636 - mae: 0.8928\n",
            "Epoch 27: saving model to GNN_MODEL/model_epoch_27.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1221s\u001b[0m 2s/step - loss: 1.4636 - mae: 0.8928 - val_loss: 1.4360 - val_mae: 0.8671\n",
            "Epoch 28/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4384 - mae: 0.8884\n",
            "Epoch 28: saving model to GNN_MODEL/model_epoch_28.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1231s\u001b[0m 2s/step - loss: 1.4384 - mae: 0.8884 - val_loss: 1.3963 - val_mae: 0.8739\n",
            "Epoch 29/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3997 - mae: 0.8715\n",
            "Epoch 29: saving model to GNN_MODEL/model_epoch_29.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 2s/step - loss: 1.3997 - mae: 0.8715 - val_loss: 1.4468 - val_mae: 0.8385\n",
            "Epoch 30/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4174 - mae: 0.8803\n",
            "Epoch 30: saving model to GNN_MODEL/model_epoch_30.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1215s\u001b[0m 2s/step - loss: 1.4174 - mae: 0.8803 - val_loss: 1.4581 - val_mae: 0.9247\n",
            "Epoch 31/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4073 - mae: 0.8795\n",
            "Epoch 31: saving model to GNN_MODEL/model_epoch_31.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1250s\u001b[0m 2s/step - loss: 1.4074 - mae: 0.8795 - val_loss: 1.3905 - val_mae: 0.8694\n",
            "Epoch 32/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4192 - mae: 0.8832\n",
            "Epoch 32: saving model to GNN_MODEL/model_epoch_32.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1191s\u001b[0m 2s/step - loss: 1.4191 - mae: 0.8832 - val_loss: 1.4173 - val_mae: 0.8945\n",
            "Epoch 33/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4267 - mae: 0.8784\n",
            "Epoch 33: saving model to GNN_MODEL/model_epoch_33.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 2s/step - loss: 1.4267 - mae: 0.8783 - val_loss: 1.4137 - val_mae: 0.8466\n",
            "Epoch 34/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3915 - mae: 0.8687\n",
            "Epoch 34: saving model to GNN_MODEL/model_epoch_34.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1241s\u001b[0m 2s/step - loss: 1.3915 - mae: 0.8687 - val_loss: 1.4088 - val_mae: 0.8422\n",
            "Epoch 35/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3639 - mae: 0.8608\n",
            "Epoch 35: saving model to GNN_MODEL/model_epoch_35.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1233s\u001b[0m 2s/step - loss: 1.3640 - mae: 0.8608 - val_loss: 1.3726 - val_mae: 0.8247\n",
            "Epoch 36/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3604 - mae: 0.8550\n",
            "Epoch 36: saving model to GNN_MODEL/model_epoch_36.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1238s\u001b[0m 2s/step - loss: 1.3604 - mae: 0.8550 - val_loss: 1.4409 - val_mae: 0.8397\n",
            "Epoch 37/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3659 - mae: 0.8593\n",
            "Epoch 37: saving model to GNN_MODEL/model_epoch_37.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 2s/step - loss: 1.3659 - mae: 0.8593 - val_loss: 1.3793 - val_mae: 0.8673\n",
            "Epoch 38/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3595 - mae: 0.8580\n",
            "Epoch 38: saving model to GNN_MODEL/model_epoch_38.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1209s\u001b[0m 2s/step - loss: 1.3595 - mae: 0.8580 - val_loss: 1.4397 - val_mae: 0.9195\n",
            "Epoch 39/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3651 - mae: 0.8621\n",
            "Epoch 39: saving model to GNN_MODEL/model_epoch_39.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1227s\u001b[0m 2s/step - loss: 1.3651 - mae: 0.8621 - val_loss: 1.4342 - val_mae: 0.8471\n",
            "Epoch 40/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3498 - mae: 0.8530\n",
            "Epoch 40: saving model to GNN_MODEL/model_epoch_40.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1236s\u001b[0m 2s/step - loss: 1.3497 - mae: 0.8530 - val_loss: 1.3674 - val_mae: 0.8142\n",
            "Epoch 41/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3366 - mae: 0.8448\n",
            "Epoch 41: saving model to GNN_MODEL/model_epoch_41.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1208s\u001b[0m 2s/step - loss: 1.3367 - mae: 0.8448 - val_loss: 1.5239 - val_mae: 0.8659\n",
            "Epoch 42/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3776 - mae: 0.8658\n",
            "Epoch 42: saving model to GNN_MODEL/model_epoch_42.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1226s\u001b[0m 2s/step - loss: 1.3776 - mae: 0.8658 - val_loss: 1.3832 - val_mae: 0.8265\n",
            "Epoch 43/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3094 - mae: 0.8351\n",
            "Epoch 43: saving model to GNN_MODEL/model_epoch_43.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 2s/step - loss: 1.3094 - mae: 0.8351 - val_loss: 1.3646 - val_mae: 0.8354\n",
            "Epoch 44/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3051 - mae: 0.8330\n",
            "Epoch 44: saving model to GNN_MODEL/model_epoch_44.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 2s/step - loss: 1.3052 - mae: 0.8330 - val_loss: 1.3430 - val_mae: 0.8141\n",
            "Epoch 45/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3062 - mae: 0.8315\n",
            "Epoch 45: saving model to GNN_MODEL/model_epoch_45.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1215s\u001b[0m 2s/step - loss: 1.3063 - mae: 0.8315 - val_loss: 1.3568 - val_mae: 0.8551\n",
            "Epoch 46/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3174 - mae: 0.8392\n",
            "Epoch 46: saving model to GNN_MODEL/model_epoch_46.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1243s\u001b[0m 2s/step - loss: 1.3174 - mae: 0.8392 - val_loss: 1.3635 - val_mae: 0.8507\n",
            "Epoch 47/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3056 - mae: 0.8368\n",
            "Epoch 47: saving model to GNN_MODEL/model_epoch_47.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1259s\u001b[0m 2s/step - loss: 1.3057 - mae: 0.8368 - val_loss: 1.3617 - val_mae: 0.8170\n",
            "Epoch 48/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.2959 - mae: 0.8289\n",
            "Epoch 48: saving model to GNN_MODEL/model_epoch_48.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1281s\u001b[0m 2s/step - loss: 1.2959 - mae: 0.8289 - val_loss: 1.3269 - val_mae: 0.8061\n",
            "Epoch 49/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.2901 - mae: 0.8264\n",
            "Epoch 49: saving model to GNN_MODEL/model_epoch_49.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1293s\u001b[0m 2s/step - loss: 1.2902 - mae: 0.8264 - val_loss: 1.3749 - val_mae: 0.8793\n",
            "Epoch 50/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.2784 - mae: 0.8225\n",
            "Epoch 50: saving model to GNN_MODEL/model_epoch_50.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1296s\u001b[0m 2s/step - loss: 1.2784 - mae: 0.8225 - val_loss: 1.3369 - val_mae: 0.8143\n",
            "Epoch 51/100\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.2837 - mae: 0.8201\n",
            "Epoch 51: saving model to GNN_MODEL/model_epoch_51.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1270s\u001b[0m 2s/step - loss: 1.2837 - mae: 0.8201 - val_loss: 1.3217 - val_mae: 0.8112\n",
            "Epoch 52/100\n",
            "\u001b[1m276/705\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m12:34\u001b[0m 2s/step - loss: 1.3349 - mae: 0.8418"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the combined model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_protein\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgnn_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_kd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.18\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_cb\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NongNam\\Documents\\AI_Builder\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train the combined model\n",
        "history = model.fit(\n",
        "    [X_protein, gnn_features],\n",
        "    y_kd,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_split=0.18,\n",
        "    callbacks=[checkpoint_cb, history_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAX8BJREFUeJzt3Qd4U2XbB/B/0qZ7L0rZZW9liIiKgIqIKM5XRQUXDlBwvCqvExe494cbXIDiKziRl6UoQ5bsIXuXUkr3Ts533U96QrqTNk3S5v+7rkNGT5PTk9DcvZ/7fh6DpmkaiIiIiLyQ0dMHQERERFQVBipERETktRioEBERkddioEJERERei4EKEREReS0GKkREROS1GKgQERGR12KgQkRERF6LgQoRERF5LQYqROUYDAY888wzTn/f/v371ffOmDGjXo6LGq8xY8agdevWLnkfepPffvtN/Rzffvutpw+FGjAGKuSV5MNefsHJ9ueff1b4uqz80KJFC/X1yy67zCPHSERE9Y+BCnm1oKAgzJw5s8L9v//+Ow4fPozAwECPHBcREbkHAxXyapdeeinmzJmDkpKSMvdL8NK7d28kJiZ67Nh8RW5urqcPwWtZLBYUFBR4+jCIGjUGKuTVbrjhBpw8eRILFy603VdUVKTGvG+88cYqP1gfeughNTQkGZeOHTvi1VdfVcNF9goLC/HAAw8gPj4e4eHhuPzyy1WWpjJHjhzBbbfdhiZNmqjH7Nq1Kz799NNa/Uzp6el4+OGH0b17d4SFhSEiIgLDhg3Dxo0bK+wrH4JSp9ChQweVXWratCmuuuoq7Nmzp8yH5VtvvaUeT/aRn+eSSy7B2rVra6ydKV8HIdflvm3btqnzGx0djXPPPVd9bdOmTaqWIjk5WT2PBIlyTuT1qex83X777UhKSlLnq02bNrjnnnvUa7d37171HG+88UaF71uxYoX62qxZs6o9h6mpqerx5fWQY+nZsyc+++wz29eLi4sRExODW2+9tcL3ZmVlqe+R18D+vfD000+jXbt26njlvfPII4+o+8ufr/Hjx+Orr75S7wHZ99dff63yOL///nsMHz7cdh7atm2L5557DmazGa5Sm2OX/xNyDiTYX7ZsWYXH/Pvvv9V7Ut6b8h4dMmQIVq1aVWG/jIwM9X9I6mvkuZs3b45bbrkFaWlpZfaT9+gLL7ygvi7PK4+3e/fuMvvs2rULV199tXpfyT6y7/XXX4/MzEyXnStqmPw9fQBE1ZFfgP3791cfXPKLU8yfP1/98pJfYm+//XaZ/SUYkYBj6dKl6oPsjDPOwIIFC/Dvf/9bfXjafzjecccd+PLLL9UH8jnnnIMlS5aoD5Xyjh8/jrPPPtv2i14CATkGeXz50Js4caJTP5N8UM+bNw/XXnut+gCXx//ggw8wcOBAFSDIh5qQDzOpv1m8eLH6WSdMmIDs7GwVtG3ZskV96Ak5DglC5PzIzyTZpz/++EN9sPTp06dW512OrX379njxxRdtAZ48rxy7fPjLh8nWrVvx4Ycfqkt5Ljk/4ujRozjrrLPUh9jYsWPRqVMnde4luMzLy1OBzoABA9QHpnzI2ZP7JGi84oorqjy2/Px8XHDBBeqDTl4POYeSdZMgSp5TzpPJZMKVV16J7777Tp3bgIAA2/fLuZcPcTmn+oeovGekFkqOt3Pnzti8ebN6r/zzzz9qf3vyPvnmm2/Uc8fFxVUogrUnr4t80D/44IPqUr73qaeeUu+bV155BXXl7LHLkOnXX3+N+++/XwUW//d//6eC2tWrV6Nbt25qH3k9zzvvPBWkSMAj51LOoZxz+f5+/fqp/XJyctR+27dvVwFrr169VIDyww8/qIBfzo1u6tSpMBqNKjiU/7svv/wyRo0ahb/++kt9XQLYoUOHqtflvvvuU+8vec/89NNP6jWNjIys87miBkwj8kLTp0+XT0dtzZo12rvvvquFh4dreXl56mvXXnutNmjQIHW9VatW2vDhw23fN2/ePPV9zz//fJnHu+aaazSDwaDt3r1b3d6wYYPa79577y2z34033qjuf/rpp2333X777VrTpk21tLS0Mvtef/31WmRkpO249u3bp75Xjr06BQUFmtlsLnOffG9gYKD27LPP2u779NNP1eO9/vrrFR7DYrGoyyVLlqh97r///ir3qe64yv+scl3uu+GGGyrsq/+c9mbNmqX2X7Zsme2+W265RTMajeq1q+qYPvjgA/V927dvt32tqKhIi4uL00aPHq1V580331Tf++WXX5b53v79+2thYWFaVlaWum/BggVqvx9//LHM91966aVacnKy7fYXX3yhjvePP/4os9/777+vvn/58uVlzpfsu3XrVs0RlZ2zu+66SwsJCVHvA538zPJeru61qYyzxy7b2rVrbfcdOHBACwoK0q688krbfSNHjtQCAgK0PXv22O47evSo+j94/vnn2+576qmn1ON99913Vb7OS5cuVft07txZKywstH39rbfeUvdv3rxZ3f7777/V7Tlz5lT785Jv4tAPeb3rrrtO/RUtf11JRkEuqxr2+eWXX+Dn56f+YrQnQ0Hyu1oyIfp+ovx+5bMj8j3//e9/MWLECHVd/mLUN/kLUP46XL9+vVM/j/wlK39d6lkTGTqRv7YlHW//WPK88lep/IVZnp69kH3kuqT+q9qnNu6+++4K9wUHB5cZkpJzIJkmoR+3/IUvf8XL+aosm6Mfk7ymkt6XDIpOMl/ymDfddFO1xyavnfzFLcOCOvmrX15L+Stf/uoXgwcPVudPMgi6U6dOqczQv/71L9t9ko2RTIRkfuxfX/l+Idk5e5L56tKlS7XHWNk5k/euPK5kISSztGPHDtSVs8cu2UkZ7tG1bNlSZa/k3Mt7Ubb//e9/GDlypMp86WTIUf7PSeZGskH6e0+G3CRzVdN7T7Jw9lktOQdCMnRCz5jIcci5IbLHQIW8ngy1XHjhhaqAVlL58sv0mmuuqXTfAwcOqKETGT6wJ7/M9a/rlxIs6MMnOgkW7J04cUKlnmWIQ47DftPrH6RewhnyYS6peRlakaBFPkzl8aQGxH48XupQ5Hj8/aseoZV95OeVegxXkuGUymprZFhF6kLkA1iOWd9PP245X/JBpg8jVCUqKkoFM/YdXRK0NGvWzPYhWxV57eTc6cFeVa+xnDepeZA6Eb1eQ94/Ur9iH6hIbYQMd5R/faUuqLLXt7JzUxV5XPkglw9iGUqRx9UDMVfUXjh77HLeypN9JTiQ1042uV7+/4F+fuW9e+jQIdt7r6bX2T4gsie1T3rgqJ9TGR77+OOP1f8H+SPgvffeY30KKaxRoQZB/pq78847kZKSomox5IPOHeQXs5APl9GjR1e6T48ePZx6TKn7ePLJJ9W4vhRWSpAhH7qSzdGfz5WqyqxUV9BpnwnQSRZEil2l3kdqfyQLJMcrNQ61OW4pupSMgDymFAJLbcO9995bIQCpC6lDkfoKyaRJlkBqSyT7IJkAnRy7PP/rr79e6WNIcWpN56YyEuBK9kUClGeffVYFxZJFkuzTo48+6pLX2tlj9xTJclbGvsD9tddeU3VGElhKVkcyZFOmTFH1T1JYS76LgQo1CPJX6V133aV+admn8str1aoVFi1apNLs9lkVPc0uX9cv5Ze8nrXQ7dy5s8zj6R1B8qEuWR1XkKLSQYMG4ZNPPqnwwWZfgCgfbFJsKBkAGdqojOwj6XLJdlSVVdH/epXHt6dnHhwhf/lKUe/kyZNVMaj9X/Tlz5d8MEuxb00kwJH9JZMiBZryl/zNN99c4/fJayfZJ3n97IOa8q+xOP/889WwhbxnpHtJilkff/zxCudQOq6kE6Uuw2WVzcoqw3qSxZHj0O3bt89lz+HssZd/vYQU3YaEhKjXQsj18v8P9PMr51sPfuS5HXmdnSFBl2xPPPGECmCl6Pr999/H888/79LnoYaFQz/UIMhf79OmTVPtszJkUN28KxJUvPvuu2Xul6EW+UWudw7pl+W7ht58880KfwnK8IGMx1f2S1lS5c6SxyzfKi2ZBelysCfPK/UG5X8WoX+/7CPXJYCoah8JHCQAKt+GKh0fzhyz/WNWdb7kg0wyFz/++KOtPbqyY9KHZqTORLIc0h0jH1COZKfkNZbMmn3AKp1O77zzjnqfSBbD/nhkmFCO54svvlD72Q/76JkiOfcfffRRheeS2qjaziNT2TmT7hZnzntNnD32lStXlqmDkmEcyWBcfPHF6nhlk+tyn7S166QzTYbpJNiT95P+3pMgae7cuRWeu/z7pCYyXFh+riR5P8jrV77NmnwPMyrUYFQ19GJPghjJVshfzfKLVlL8kkaWX7wytKLXpMjQhXxIyoeGjINLe7JkDMrP7aC3VkpRovzVL8NPUkgpGQz5hS/ZG7nuDGk5lqEAqXGR55V2Uskq2Bcv6kMjn3/+uRq7l/ZRKUCUDx55ThkikSJI+VklCyEBl/y1rA/DSHuyfE1aaIW0LcvPIZdS5CpBi/wl7Sj5cJKsgLSVSoZHaknkvFaWHZChLfmaBAx6y+yxY8dUMCbFmPbDdvIzyrHL+X3ppZccOhZ5TBnOkWGCdevWqfZgyVItX75cBU7l65MkMJEgRgqO5cNPr2XRyfmTYEkKiOU45K94CXYlgyD3S8aqNm3e8tpKNkvetzKMIYGyBEvOfohXx9ljl5oSqf+wb08W9oGuZC+k4FiCEnmfSUAp51sCBnn9dTIEKOddWtllGFOKdOX/ggzhSRbEfnitJpLpkveqPJbUzEjQIudK/0OBfJyn246IampPrk759mSRnZ2tPfDAA1pSUpJmMpm09u3ba6+88oqtZVKXn5+v2npjY2O10NBQbcSIEdqhQ4cqbQs9fvy4Nm7cOK1FixbqMRMTE7UhQ4ZoH374oW0fZ9qTH3roIdXyHBwcrA0YMEBbuXKlNnDgQLWVb299/PHHtTZt2tieV1qt7VtHS0pK1M/XqVMn1VYaHx+vDRs2TFu3bl2Zx5E2a2mnljbT6667TktNTa2yPfnEiRMVjvvw4cOqjTUqKko9jrSJS9tqZedL2l6lTVmORdqupR1Yzp99i6qua9euqsVWHt9R8nrceuutqp1Zfubu3btXed7ldZfXrbK2dfv25pdeekkdixxvdHS01rt3b23y5MlaZmambT95DPk5HCXtwWeffbZ6neX9+Mgjj9japqV1t67tybU5dmnrlv8Tsu+ZZ55Z5jh069ev14YOHaravaWVWqYDWLFiRYX9Tp48qY0fP15r1qyZeh2aN2+ufha9lV9vTy7fdlz+/8revXu12267TWvbtq1ql46JiVHPuWjRIofOMzVuBvnH08ESEfmuM888U9XXSEaL6o9kdMaNG1fpUCKRN2ONChF5jNSxbNiwQQ0BERFVhjUqROR2Upgs9SXSkipdOeULXImIdMyoEJHbSRGmFBNLYa6s4yTzixARVYY1KkREROS1mFEhIiIir8VAhYiIiLxWgy6mlYmtjh49qiZ4cuXU10RERFR/pOpEljqRRVVrWt+rQQcqEqR4y6JbRERE5BxZxqGmRScbdKCiT5UtP6i+/gQRERF5N1nfSRIN5Ze8aHSBij7cI0EKAxUiIqKGxZGyDRbTEhERkddioEJERERei4EKERERea0GXaNCRESNh9lsVssqUMNnMpng5+fX8AMVeVM+88wz+PLLL5GSkqL6qceMGYMnnniC86IQEfnQnBryGZCRkeHpQyEXioqKQmJiYp0/zz0aqLz00kuYNm0aPvvsM3Tt2lUt+S4LlUVGRuL+++/35KEREZGb6EFKQkICQkJC+IdqIwg88/LykJqaqm7LCukNNlBZsWIFrrjiCgwfPlzdbt26tVpJdfXq1Z48LCIicmNmXQ9SYmNjPX045CLBwcHqUoIVeW3rMgzk0WLac845B4sXL8Y///yjbm/cuBF//vknhg0bVun+hYWFapIY+42IiBouvSZFMinUuISUvqZ1rTvyaEblscceU8FGp06dVLQlkfULL7yAUaNGVbr/lClTMHnyZLcfJxER1S8O9zQ+Bhe9ph7NqHzzzTf46quvMHPmTKxfv17Vqrz66qvqsjKTJk1CZmambZOp84mIiKjx8mhG5d///rfKqlx//fXqdvfu3XHgwAGVORk9enSF/QMDA9VGRETUGEmt5sSJE9VGXpBRkarg8ss7yxCQxWLx2DERERE5MqxR3SZTb9TGmjVrMHbsWJcfb0Pm0YzKiBEjVE1Ky5YtVXvy33//jddffx233XabJw8LhSVmnMwpUteToqyVy0RERLpjx47Zrn/99dd46qmnsHPnTtt9YWFhZdp1pQbT37/mj9z4+Ph6ONqGzaMZlXfeeQfXXHMN7r33XnTu3BkPP/ww7rrrLjz33HOePCx8v+Eozpm6BJO+2+zR4yAiIu8kE5npm8z9JVkU/faOHTsQHh6O+fPno3fv3qpkQTpa9+zZo6bkaNKkiQpk+vbti0WLFlUY+nnzzTdttw0GAz7++GNceeWVqoumffv2+OGHH+BLPJpRkRdSXhD7F8UbRAab1GVWAadyJiJyN8lA5BebPfLcwSY/l3WrSA2mNIgkJycjOjpaNYBceumlaiRBgpfPP/9cjSxIJkZGFqoyefJkvPzyy3jllVfUH/jSGSv1nDExMfAFXOunEhFB1kAlM5+BChGRu0mQ0uWpBR557m3PDkVIgGs+Gp999llcdNFFttsSWPTs2dN2W0YP5s6dqzIk48ePr/JxxowZgxtuuEFdf/HFF/H222+riVEvueQS+AKunlxdRiW/xNOHQkREDVSfPn3K3M7JyVElDlLqIOvgyPDP9u3bcfDgwWofp0ePHrbroaGhiIiIsE1P7wuYUalERLD1tGTlF6sUJCciIiJy7/CLZDY89dyuIkGFPQlSFi5cqIaD2rVrp6aZlzrNoiJr80Z1KxHbk88kX+qOZaBSTUalyGxBYYkFQS584xIRUfXkg9hVwy/eZPny5WoYRwpj9QzL/v37PX1YXo9DP5UIDfCHsTSJwjoVIiJyBenY+e6777Bhwwa1tt2NN97oU5mR2mKgUgmj0YAIW50KAxUiIqo7mSdMun9kQV7p9hk6dCh69erl6cPyegZNijAaKFnQUPrXZd0fKS5ypfNfXoqD6Xn49u7+6NPaN1rAiIjcraCgAPv27UObNm0QFBTk6cMhN722znx+M6NSBc6lQkRE5HkMVGro/GGNChERkecwUKkC51IhIiLyPAYqVeDstERERJ7HQKXGjAoDFSIiIk9hoFIFvT2ZGRUiIiLPYaBSBds8Kuz6ISIi8hgGKlWICGLXDxERkacxUKkCu36IiIg8j4FKFVijQkRE9emCCy7AxIkTbbdbt26NN998s8YFG+fNm1fn53bV47gDA5UqcGZaIiKqiqzVc8kll1T6tT/++EMFAps2bXLqMdesWYOxY8fClZ555hmcccYZFe4/duwYhg0bhoaAgUoN86hkF5TAbGmwyyEREVE9uP3227Fw4UIcPny4wtemT5+OPn36oEePHk49Znx8PEJCQuAOiYmJCAwMREPAQKWGKfRFTgHrVIiI6LTLLrtMBRYzZswoc39OTg7mzJmDkSNH4oYbbkCzZs1U8NG9e3fMmjWr2scsP/Sza9cunH/++WpBvy5duqjAqLxHH30UHTp0UM+RnJyMJ598EsXF1pEAObbJkydj48aNKsMjm3685Yd+Nm/ejMGDByM4OBixsbEqsyM/i27MmDHqZ3r11VfRtGlTtc+4ceNsz1WfTn8aUxmB/n4IMhlRUGxRdSqRIdYMCxER1TNNA4rzPPPcphD5FK9xN39/f9xyyy3qg//xxx9XH/xCghSz2YybbrpJXZdAQlYH/vnnn3HzzTejbdu2OOuss2p8fIvFgquuugpNmjTBX3/9pVYZtq9n0YWHh6tjSEpKUsHGnXfeqe575JFH8K9//QtbtmzBr7/+ikWLFqn9ZcXi8nJzczF06FD0799fDT+lpqbijjvuwPjx48sEYkuXLlVBilzu3r1bPb4MK8lz1icGKjXUqRQUF7JOhYjInSRIeTHJM8/9n6NAQKhDu95222145ZVX8Pvvv6vCWH3Y5+qrr0arVq3w8MMP2/a97777sGDBAnzzzTcOBSoSWOzYsUN9jwQh4sUXX6xQV/LEE0+UycjIc86ePVsFKpIdCQsLU0GVDPVUZebMmSgoKMDnn3+O0FDrz/7uu++qOpyXXnpJBUsiOjpa3e/n54dOnTph+PDhWLx4cb0HKhz6qQbX+yEioqrIh/U555yDTz/9VN2WLIMU0kr9imRVnnvuOTXkExMTowIGCToOHjzo0GNv374dLVq0sAUpQjIe5X399dcYMGCACkTkOSRwcfQ57J+rZ8+etiBFyGNKVmfnzp22+7p27aqCFJ1kVyT7Ut+YUXFkdloGKkRE7h1+kcyGp57bCRKUSLbkvffeU9kUGdoZOHCgykS89dZbquZEghUJAmTopqioyGWHunLlSowaNUrVocjQjQzrSDbltddeQ30wmcqWQMhwlwQz9Y2BigMtysyoEBG5kdR7ODj84mnXXXcdJkyYoIZPZOjknnvuUR/gy5cvxxVXXKFqVYR8oP/zzz+qKNYRnTt3xqFDh1QbsWQuxKpVq8rss2LFCjXEJDUyugMHDpTZJyAgQGV3anouqUWRWhU9qyLHbzQa0bFjR3gah34cmEafNSpERFQZGW6RotJJkyapoEK6Y0T79u1Vl44EEzK0ctddd+H48eMOP+6FF16ounlGjx6tunZkSMk+INGfQ4Z5JIuyZ88evP3225g7d26ZfaRuZd++fdiwYQPS0tJQWFhY4bkkKyOdRfJcUnwrxbKSJZLiX70+xZMYqFSDGRUiInJk+OfUqVNq+EWvKZFakV69eqn7pNBWakikvddRks2QoCM/P18V30oXzgsvvFBmn8svvxwPPPCA6s6R7hsJiqQ92Z4U9srEdIMGDVLt1JW1SEtrs9TPpKeno2/fvrjmmmswZMgQVTjrDQyaJn1gDVNWVpYak5O2LWn/crXX/rcT7yzZjZvPboXnRnZz+eMTEfk66TaRv/jbtGmj/qon33hts5z4/GZGpRqcRp+IiMizGKhUg+3JREREnsVApRpsTyYiIvIsBioOrPfDjAoREZFnMFBxqEaFixISEdWnBtzXQfX8mjJQqQZrVIiI6pc+22lenocWIaR6o7+m5We0dRZnpq2GvmJyUYkFBcVmBJlOr3FARER1J2vHREVF2daMkTk99JWIqWGSTIoEKfKaymtrvz5QbTBQqUZYgL+ayVmyV1JQy0CFiMj19JV93bHAHbmPBCnVrdrsKAYq1TAaDWr4R4Z+ZC6VhAhORkRE5GqSQZH1bBISElBczKH2xsBkMtU5k6JjoOJA548EKqxTISKqX/LB5qoPN2o8WEzraOdPPjt/iIiI3I2BSg3Y+UNEROSjgYosPy1jk+W3cePGwVtwvR8iIiLP8WiNypo1a2A2m223t2zZgosuugjXXnstvC6jksdAhYiIyKcClfj4+DK3p06dirZt22LgwIHwtrlUmFEhIiJyP6/p+ikqKsKXX36JBx98sMrJfgoLC9Wmy8rKqvfjigjiej9ERETw9WLaefPmISMjA2PGjKlynylTpiAyMtK2tWjRot6Pi10/REREnuM1gconn3yCYcOGISkpqcp9Jk2ahMzMTNt26NChej+uiNJAhRkVIiIiHx36OXDgABYtWoTvvvuu2v0CAwPV5k56oMIaFSIiIh/NqEyfPl1NnTx8+HB4G86jQkRE5MOBisViUYHK6NGj4e/vFQmeKmpUGKgQERH5XKAiQz4HDx7EbbfdBm9d60dkF5bAYtE8fThEREQ+xeMpjIsvvhia5r0BgD70I4cowYqeYSEiIiIfyKh4uyCTHwL9raeJwz9ERETuxUDFAXoWhQW1RERE7sVAxZkWZQYqREREbsVAxQFcQZmIiMgzGKg4sd4Pp9EnIiJyLwYqDmCNChERkWcwUHEAp9EnIiLyDAYqDmBGhYiIyDMYqDgx6Ru7foiIiNyLgYoT0+gzo0JEROReDFScak9m1w8REZE7MVBxYuiHGRUiIiL3YqDiAM5MS0RE5BkMVBzArh8iIiLPYKDiREalsMSCgmKzpw+HiIjIZzBQcUB4oD8MBut1TvpGRETkPgxUHGA0GlSwIrjeDxERkfswUHGQPvzDOhUiIiL3YaDi9FwqDFSIiIjchYGKgziNPhERkfsxUHE2o8JAhYiIyG0YqDiI6/0QERG5HwMVB3G9HyIiIvdjoOLsej95zKgQERG5CwMVB0WGsOuHiIjI3RioOIgrKBMREbkfAxUHcR4VIiIi92Og4iB2/RAREbkfAxWn51Fh1w8REZG7MFBxdmbagmJYLJqnD4eIiMgnMFBxclFCTQNyiphVISIicgcGKg4KMvkhwN96ujiXChERkXswUHECO3+IiIjci4GKEyKCrJ0/LKglIiJyDwYqtciosEWZiIjIPRio1KKglkM/RERE7sFApVZzqTBQISIicgcGKrWZS4WBChERkVswUHECa1SIiIjci4FKLdb7ySpg1w8REZFPBCpHjhzBTTfdhNjYWAQHB6N79+5Yu3YtvBEzKkRERO5lTRF4yKlTpzBgwAAMGjQI8+fPR3x8PHbt2oXo6Gh4I9aoEBER+VCg8tJLL6FFixaYPn267b42bdrAWzGjQkRE5ENDPz/88AP69OmDa6+9FgkJCTjzzDPx0UcfVbl/YWEhsrKyymzuxHlUiIiIfChQ2bt3L6ZNm4b27dtjwYIFuOeee3D//ffjs88+q3T/KVOmIDIy0rZJNsadmFEhIiJyL4OmaRo8JCAgQGVUVqxYYbtPApU1a9Zg5cqVlWZUZNNJRkWClczMTERERNT78cqqyT2f/Z+6vvP5SxDo71fvz0lERNTYyOe3JBwc+fz2aEaladOm6NKlS5n7OnfujIMHD1a6f2BgoPqB7Dd3CitdlFBwYUIiIqL659FARTp+du7cWea+f/75B61atYI38jMaEK6voMw6FSIiosYdqDzwwANYtWoVXnzxRezevRszZ87Ehx9+iHHjxsFb6S3KrFMhIiJq5IFK3759MXfuXMyaNQvdunXDc889hzfffBOjRo2Ct+LChERERD4yj4q47LLL1NbQptFnRoWIiMgHptBvaGwZFa73Q0REVO8YqDiJ0+gTERG5DwMVJ7FGhYiIyH0YqNRyGn3WqBAREdU/Biq1rlFhoEJERFTfGKg4iV0/RERE7sNApdY1Kuz6ISIiqm8MVJzEmWmJiIjch4GKk1ijQkRE5D4MVGrZ9SPtyZqmefpwiIiIGjUGKrXMqFg0IKeQdSpERET1iYGKkwL9jQjws542TqNPRERUvxioOMlgMJye9C2PdSpERET1iYFKHeZSYUEtERFR/WKgUoc6FbYoExER1S8GKrXAFZSJiIjcg4FKLTCjQkRE5B4MVOpUo8KuHyIiovrEQKVO6/0wo0JERFSfGKjUAmtUiIiI3IOBSi2wRoWIiMg9GKjUZb0fzqNCRERUrxio1AIzKkRERO7BQKVONSrs+iEiIqpPDFRqgRkVIiIi92CgUod5VPKLzSgqsXj6cIiIiBotBiq1EF469CNYUEtERFR/GKjUgp/RgPDA0tlpOfxDRERUbxio1LFFmXUqRERE9YeBSp3nUmHnDxERUX1hoFJLkaUFtcyoEBER1R8GKrXE9X6IiIjqHwOVWmKNChERUf1joFLHSd/YnkxERFR/GKjUEod+iIiI6h8DlToW03K9HyIiIi8KVFq3bo1nn30WBw8ehC9jjQoREZEXBioTJ07Ed999h+TkZFx00UWYPXs2CgsL4WuiQwPU5am8Ik8fChERUaNVq0Blw4YNWL16NTp37oz77rsPTZs2xfjx47F+/Xr4irjQQHV5MoeBChERkdfVqPTq1Qtvv/02jh49iqeffhoff/wx+vbtizPOOAOffvopNE2r8TGeeeYZGAyGMlunTp3QEMSGWTMqJ3MLHfpZiYiIyHnWitBaKC4uxty5czF9+nQsXLgQZ599Nm6//XYcPnwY//nPf7Bo0SLMnDmzxsfp2rWr2td2QP61PiS3iikd+ik2a2oafb1dmYiIiFzH6ahAhnckOJk1axaMRiNuueUWvPHGG2UyIVdeeaXKrjh0AP7+SExMREMTZPJTKyhnF5bgZE4hAxUiIiJvGPqRAGTXrl2YNm0ajhw5gldffbXCcE2bNm1w/fXXO/R48lhJSUmqOHfUqFENqptIH/5JY50KERGRd2RU9u7di1atWlW7T2hoqMq61KRfv36YMWMGOnbsiGPHjmHy5Mk477zzsGXLFoSHh1fYX7qL7DuMsrKy4EmxYYHYfzJPZVSIiIjICzIqqamp+OuvvyrcL/etXbvWqccaNmwYrr32WvTo0QNDhw7FL7/8goyMDHzzzTeV7j9lyhRERkbathYtWsCTYkvrVNJymVEhIiLyikBl3LhxOHToUIX7ZRhIvlYXUVFR6NChA3bv3l3p1ydNmoTMzEzbVtlxuDujIphRISIi8pJAZdu2bao1ubwzzzxTfa0ucnJysGfPHjUvS2UCAwMRERFRZvOkOL1FmTUqRERE3hGoSLBw/PjxCvdLjYmzrcUPP/wwfv/9d+zfvx8rVqxQ3UJ+fn644YYb0BDoQz8ylwoRERF5QaBy8cUX24ZgdFJXInOnyJT6zpA5VyQokWLa6667DrGxsVi1ahXi4+PREOhDP+z6ISIi8pKuH2lHPv/881Xnjwz3CJlSv0mTJvjiiy+ceixZJ6ghs81OyxoVIiIi7whUmjVrhk2bNuGrr77Cxo0bERwcjFtvvVVlRkwm35r0LE4vpmXXDxERUb2o1Xz1Mk/K2LFj4ev0QCUjrxjFZgtMfrVeOomIiIgqUeuFdaTDR2aRLSoqm024/PLL4Suigk0wGgCLBpzKLUJCRJCnD4mIiKhRqdXMtNKds3nzZrXasb5ysFwXZrMZvsJoNCAmNBBpOYWqoJaBChERkWs5PVYxYcIEtZaPzFAbEhKCrVu3YtmyZejTpw9+++03+BrbXCpsUSYiIvJ8RmXlypVYsmQJ4uLi1OrJsp177rlqevv7778ff//9N3zJ6c4fFtQSERF5PKMiQzv6goESrBw9elRdl3blnTt3wtfEhupzqTCjQkRE5PGMSrdu3VRbsgz/yOrHL7/8MgICAvDhhx8iOTkZvkbPqHDSNyIiIi8IVJ544gnk5uaq688++ywuu+wynHfeeWpW2a+//hq+xjaXCjMqREREng9Uhg4darverl077NixA+np6YiOjrZ1/viS0+v9MKNCRETk0RqV4uJitfDgli1bytwfExPjk0GK/Xo/zKgQERF5OFCRKfJbtmzpU3Ol1IQ1KkRERF7U9fP444+rlZJluIeAuNKuH5lHRZ/8joiIiDxUo/Luu+9i9+7dSEpKUi3Jsu6PvfXr18MXMyoFxRbkFZkRGljrVQmIiIioHKc/VUeOHOnstzRqIQF+CDIZVaAik74xUCEiInIdpz9Vn376aRc+fcMnRcQy6duRjHyk5RaiZWyIpw+JiIjId2tUqJr1flhQS0RE5NmMiqztU10rsi92BHHSNyIiIi8JVObOnVthbhVZiPCzzz7D5MmT4YtsCxNy0jciIiLPBipXXHFFhfuuueYadO3aVU2hf/vtt8NXJ33jwoREREReWqNy9tlnY/HixfBFtmn0WaNCRETkfYFKfn4+3n77bTRr1gy+yFajksuMChERkUeHfsovPiizsWZnZyMkJARffvklfLpGhRkVIiIizwYqb7zxRplARbqA4uPj0a9fPxXE+CKZR0WwRoWIiMjDgcqYMWNcfAiNZx6V9NwimC0a/Iy+uZI0ERGRx2tUpk+fjjlz5lS4X+6TFmVfFF1aTGvRgIw8Dv8QERF5LFCZMmUK4uLiKtyfkJCAF198Eb7I5GdEVIhJXedcKkRERB4MVA4ePIg2bdpUuF9WUpav+Sq9RZl1KkRERB4MVCRzsmnTpgr3b9y4EbGxsfBV+qRv7PwhIiLyYKByww034P7778fSpUvVuj6yLVmyBBMmTMD1118PX3V6YUJmVIiIiDzW9fPcc89h//79GDJkCPz9rd9usVhwyy23+GyNin2LMmtUiIiIPBioBAQEqDV9nn/+eWzYsAHBwcHo3r27qlHxZfqkb2kc+iEiIvJcoKJr37692qh8jQqHfoiIiDxWo3L11VfjpZdeqnD/yy+/jGuvvRaNQkkhkL4XOLnH4W+J0xcm5NAPERGR5wKVZcuW4dJLL61w/7Bhw9TXGoWNs4C3zwR+neTwt8SFM6NCRETk8UAlJydH1amUZzKZkJWVhUYhPMl6mXXU6XlU2J5MRETkwUBFCmelmLa82bNno0uXLmgUIppaL7OPOl2jkl1YgoJic30dGRERkU9xupj2ySefxFVXXYU9e/Zg8ODB6r7Fixdj5syZ+Pbbb9GoMip5J631Kv7WIKQ6EUH+MPkZUGzW1OKESVHB9X+cREREjZzTGZURI0Zg3rx52L17N+6991489NBDOHLkiJr0rV27dmgUQmIAv9LgJPuYQ99iMBhOz6XC4R8iIiLPBCpi+PDhWL58OXJzc7F3715cd911ePjhh9GzZ080CgbD6eGfLMcClbJzqbCgloiIyGOBipAOn9GjRyMpKQmvvfaaGgZatWpVrQ9k6tSpKisxceJEeFdB7RGn61QYqBAREXmgRiUlJQUzZszAJ598ojp8JJNSWFiohoLqUki7Zs0afPDBB+jRowe8r6DW8YwK51IhIiLyUEZFalM6duyoVk5+8803cfToUbzzzjt1PgBpdx41ahQ++ugjREdHw2uE137oh3OpEBERuTlQmT9/Pm6//XZMnjxZ1aj4+fm55ADGjRunHu/CCy+EV4loVusWZRbTEhERuTlQ+fPPP5GdnY3evXujX79+ePfdd5GWllanJ5e5V9avX48pU6Y4tL8MM8mQk/1Wb2pTTFs69JPGoR8iIiL3Bipnn322Gp45duwY7rrrLhVkSCGtxWLBwoULVRDjjEOHDmHChAn46quvEBQU5ND3SEATGRlp21q0aAFvmp02jgsTEhERuZRB0zSttt+8c+dOVVj7xRdfICMjAxdddBF++OEHh75XCnCvvPLKMkNIZrNZdf4YjUaVPSk/vCT3yaaTjIoEK5mZmYiIiIBLZRwE3uwOGE3AE6mAseaYbtPhDFz+7nIkRgRh1X+GuPZ4iIiIGgn5/JaEgyOf37VuTxZSXCurJh8+fBizZs1y6nuHDBmCzZs3Y8OGDbatT58+qrBWrldWAxMYGKh+IPut3oQlWi8txdYZap2pUcktRB3iPyIiIqrtFPqVkaBi5MiRanNUeHg4unXrVua+0NBQxMbGVrjfI/wDgNAEIDfVWlAbFu9wjYpMo59VUILIYJMbDpSIiKjxqlNGpdFzsqA2yOSHsEBr7Mc6FSIiIi/JqLjKb7/9Bq8iBbXHNjo5O20AcgpL1KRvyTUnYYiIiKgazKi4enZadv4QERG5DAOV6kQk1X4uFU76RkREVGcMVByZS4Wz0xIREXkEAxWHimmdmfRNX5iQQz9ERER1xUDFodlpazP049pAJTWrAMVmi0sfk4iIyNsxUHEko1KYCRTlOjX048oald2pOeg/dQnGz1zvssckIiJqCBioVCcwAggIcyqrIu3Jru76Wb47DWaLhnUHTrnsMYmIiBoCBirVMRiAcL1F+ahz7ckuXEF5y5FMW5ZG5mghIiLyFQxUXFxQq9eoZOQVu6ymZMvRLNv1Q+l5LnlMIiKihoCBisMFtY4FKlEhATAarNdPuSCrUlBsxq7j2bbbB04yUCEiIt/BQMXRSd8cnJ3Wz2hAjAsnffvneDZKLKdXYmZGhYiIfAkDFYdnp3Vi0rdQvU6l7gW1W46cHvYRBxmoEBGRD2GgUhNbMa0Tc6nYOn/qnlHZcjSzzERyBxioEBGRD2GgUg+z056eS6XuGZWtpR0/Q7smqksO/RARkS9hoOJoMW3OccBc4lTnT11blKVraHuKtZB2eHdrwHT4VJ6aU4WIiMgXMFCpSVgCYPADNAuQm+rcej91zKjIjLRFJRaEB/rjrDYxMPkZUGzWcCwzv06PS0RE1FAwUKmJ0Q8IT3RydlrXrKCsT/TWJSkC/n5GtIgOUbdZUEtERL6CgYozBbVZR5yanTatjkM/W0sneuvWLFJdtogpDVQ4lwoREfkIBirOFNRmu3e9n62lHT/dmkWoy1axzKgQEZFvYaDiiIhmTnX+xIXWfejHYtFOZ1SSrBmVlqUZFbYoExGRr2CgUg9zqegZlfxiM3JruYjgvpO5yCsyI8hkRHJ8WJmhH7YoExGRr2CgUg+z04YE+KkAoy5ZFVshbdMINS2/4NAPERH5GgYqThXTOhaoGAwG2zT6abWcRr98Ia3Qu35kZebM/OJaPS4REVFDwkDF2YUJNc3JuVTqllHR61NEaKC/raOIwz9EROQLGKg4k1EpzgMKrAGE43OpOJ9R0TTNFqh0Le340bWMCVaXB9iiTEREPoCBiiMCQoCgKOcKauswjf7hU/nIKihBgJ8R7RPCy3ytVWyoumSdChER+QIGKvVUUFuXhQn1bErHxHAE+Jd9iWyTvqXnOv24REREDQ0DlXoqqK1LjcqWchO92dPnUmFGhYiIfAEDldoU1DozO20tun62HLF2/HS1K6TVsUWZiIh8CQOV+hr6qeXstPaFtPatyeUzKkczClBstjj12ERERA0NA5V6np02zclA5XhWoSrAlUneOiWWLaQVCeGBCPQ3wmzRcDQj36nHJiIiamgYqNRTRkWf7yQ9t1Ct2+MoPZvSPiEMQSa/SieTs635wxZlIiJq5Bio1FMxbXSINaMiMUqGE7PI6oW0ldWn6FhQS0REvoKBirMrKOelASU1F8hKW3FksMnpSd/0QtrKOn50LUsLajk7LRERNXYMVBwVEgP4WYdzkJ3iVIuyM3UqW22tyTVnVDj0Q0REjR0DFUcZDEB4opMFtc5N+ib7HcssUE/VuWnVGRW2KBMRka9goFKrgtojTk76VujUislt4kIRFujvUI2KtDMTERE1VgxUahWoHHNuLhUH1/upbMXkyjSPtgYqOYUlOJXneKEuERFRQ8NAxYvmUjldn1L1sI+QtuXEiCB1/cBJrvlDRESNFwMVNyxM6OjQj63jp4aMimCLMhER+QKPBirTpk1Djx49EBERobb+/ftj/vz5aCwZFZlFVqw/mFFjQW1mXrEt6KhuDhUdW5SJiMgXeDRQad68OaZOnYp169Zh7dq1GDx4MK644gps3boVjaGY9rz2cUiOD1VByviZ61FSzdo8W49Zh31axAQjMsQ6/0p12KJMRES+wKOByogRI3DppZeiffv26NChA1544QWEhYVh1apV8O4VlFNk9cAadw8J8MeHN/dGaIAfVu1Nx0u/7qhy361ODPsItigTEZEv8JoaFbPZjNmzZyM3N1cNAXmlsNJ5VMxFQN5Jh76lXUI4Xruup7r+0R/78MPGo9VOnV/dRG/2WrBGhYiIfIDHA5XNmzerLEpgYCDuvvtuzJ07F126dKl038LCQmRlZZXZ3Mo/AAiNd6qgVlzSrSnuuaCtuv7ot5uwIyWrytbkrknVd/zoWpUGKilZBSgoNjt8LERERA2JxwOVjh07YsOGDfjrr79wzz33YPTo0di2bVul+06ZMgWRkZG2rUWLFl5fUKt7+OKOOLddHPKLzbjri3XItFuoMLewBHvTch0upBUxoQFqSElGoI5k5Dt1LERERA2FxwOVgIAAtGvXDr1791aBSM+ePfHWW29Vuu+kSZOQmZlp2w4dOuS5xQkdLKjV+RkNePuGM9EsKlgVwD7w9QZYZGllANuPZamAQ+ZGiS/tFKqJwWA4PfzDgloiImqkPB6olGexWNQQT2VkeEhvZdY3t4to6tTstOWzIB/c3BuB/kYs2ZGKt5fsKjsjbQ0TvZXHgloiImrsql5Qxg0kQzJs2DC0bNkS2dnZmDlzJn777TcsWLAAXitc7/xxvEbFnhTLvnBldzw8ZyPeXLQL3ZtFYkvpGj+ODvvo2KJMRESNnUcDldTUVNxyyy04duyYqjmRyd8kSLnooovgteqQUdFd07s5Nh3OwOcrD2Di1xsQXroAoaMdP7qWsaHqkhkVIiJqrDwaqHzyySdocGpZTFveE8O7qNWS1x04heyCkloN/ZyeRp/r/RARUePkdTUqXq+WxbTlBfgb8X+jetmKZ2NDA2wLDTrKfr0fzYEJ6IiIiBoaBiq1HfopyASK6jbk0iQiCNNG9UJksAkjeiapTh5nSAeR0QAUFFtwwsGFD4mIiBoSjw79NEiBEYApFCjOtQ7/xFoncqutPq1jsO6JC+HvZ6xVVqZpZLCaR0ValBPCncvIEBEReTtmVJwlWQ9bQW3tOn/Kq02QomOLMhERNWYMVOq0irJrApW6YIsyERE1ZgxUPDCXiiu1LM2oHGJGhYiIGiEGKh6aS8VV7Dt/iIiIGhsGKg09o6IP/TBQISKiRoiBSgPPqLSKsc5OeyK7EPlFZk8fDhERkUsxUGngxbSRISZEBFm7zDn8Q0REjQ0DlboM/eQcByyez2K04po/RETUSDFQqY2wBMDgB2hmICfVi1qUueYPERE1LgxUasPoB4Q18Z6CWrYoExFRI8VApc51Kp4vqGWLMhERNVYMVGrLxdPo1wVblImIqLFioNKI5lI5nJ4Pi0Xz9OEQERG5DAOVRjCXStPIIPgbDSgyW5CSVeDpwyEiInIZBiq1FdHMenlsI2CxePRQZPXl5tHB6jrrVIiIqDFhoFJbbQcDgRHAie3Ahi89fTRowYJaIiJqhBio1FZoHHDBJOv1RZOB/Azv6Pw5yUCFiIgaDwYqdXHWnUB8JyAvDfhtikcPpVXpXCrMqBARUWPCQKUu/EzAJVOt11d/BBzf5vGMyr40zk5LRESNBwOVumo7COg8wjqd/vxHAM0z7cHdm0epyy1HM5Gazc4fIiJqHBiouMLFLwD+QcD+P4Bt8zxyCM2igtGzRZSKkxZsSfHIMRAREbkaAxVXiG4FDJhovb7gCaDIM3Uiw7snqsufN3t+bhciIiJXYKDiKudOBCJbAlmHgT/f8MghDOtmnYRu9b50nMgu9MgxEBERuRIDFVcxBQNDn7deX/4WcGq/R+ZS6dk8EjKL/q9bOfxDREQNHwMVV+p8OdBmIGAuBBY87pFDuLS7NavyyyYO/xARUcPHQMWVDAZg2MuAwQ/Y8ROwe7HHApW/9p1EWg6Hf4iIqGFjoOJqCZ2AfndZr89/FCgpcvvwT4/S4Z8FHP4hIqIGjoFKfbjgMSA0Hji5C1j9geeGf9j9Q0REDRwDlfoQFAkMedp6/beXgGz3ZjaGlwYqK/ecxEkO/xARUQPGQKW+nDEKSOoFFGUD34wGTvzj1uGf7s304Z/jbnteIiIiV2OgUl+MRmD4a9YZaw+tAqb1t3YCFWS55ek5/ENERI0BA5X61KwXcO9KoMMwwFICrHwXeLcPsGEWYLHU61NfWjpL7cq9J5Ge696CXiIiIldhoFLfYpKBG2cDo74FYtoCOceBeXcDnw4Fjm6ot6dtFRuKrkkRMFs0dv8QEVGDxUDFXdpfZM2uXPgMYAoFDq8GPrwA+HECkHuyXp6Swz9ERNTQMVBxJ/9A4NwHgPvWAt2vBaAB62YA75wJrPsMaunjeuj+WbGHwz9ERNQwMVDxhIgk4OqPgVt/BRK7AwWZwI/3A9/cDOSlu+xpWseFoktT6/DP/zj8Q0REDRADFU9q1R8Y+ztw0bOA0QRs/xF4/1xg/58ue4rhPaxZlZ85/ENERA2QRwOVKVOmoG/fvggPD0dCQgJGjhyJnTt3wqcY/YABE4A7FlqLbbOOAJ+NAJY8D5hLXFanIsM/p7xw+Of7DUewZr/rskhERNS4eDRQ+f333zFu3DisWrUKCxcuRHFxMS6++GLk5ubC5ySdCdy1DDjjJkCzAMteAaYPA04dqNPDtokLRWd9+Gebdw3//LHrBCbM3oBbp69BbmHdgzIiImp8PBqo/PrrrxgzZgy6du2Knj17YsaMGTh48CDWrVsHnxQYBox8D7j6EyAwwtoZJENBm7+t08MOL51T5ZfN3hWovP/7HnWZU1iC+Vu869iIiMg7eFWNSmZmprqMiYmBT+t+DXD3n0Dzs4DCLOC/twPz7gUKs+s0/LN8dxoy8rxj+Gfz4Uws3326LXvO2kMePR4iIvJOXhOoWCwWTJw4EQMGDEC3bt0q3aewsBBZWVlltkYruhVw63zg/EcAgxHY8BXwagdgzq3WotvifIcfKjk+DJ0Sw1Gihn+8Y+2f95dZsynntI2FwQD8tS8dB0/mefqwiIjIy3hNoCK1Klu2bMHs2bOrLb6NjIy0bS1atECj5ucPDH4cGP2TtdC2OA/Y+h3w9U3AK+2A/94B7PgFKCl0eE4Vb5j87cDJXMwvPY4nL+uCc9vFqevfrj9c68eUGhzNxfPQEBGR53lFoDJ+/Hj89NNPWLp0KZo3b17lfpMmTVLDQ/p26JCPDBe0HgDctw64cwlwzn1AZAugKAfYPAeYfYM1aPnuLuCfBUBJ5UM7l/Y4PfyTmVcMT/pw2V61svMFHeNVoe81va2v+X/XHYZFvuAk6WY6/+WluPb9lbX6fiIi8l4eDVTkL2AJUubOnYslS5agTZs21e4fGBiIiIiIMpvPkPGRZr2Bi58HJm4Gbl8EnD0OCE+y1rFsmg3MvA54pS3w7W3Alv+WWam5benwT7HZs90/J7ILMWedNXNy98C26nJo10SEB/njSEa+WkTRWZ/8uU9979oDp/Dn7jSXHzMREflooCLDPV9++SVmzpyp5lJJSUlRW36+4/UXPkmClhZ9gUteBB7YCty2AOh3NxCWaA1aJEiRYEWCli+vAdZOB7KP24pqf9h41GOH/tmK/SgqseCMFlHo18ZaNB1k8sOInknq+relQYyjMvOL1WPqPl9Zt3buQ+l5SMksqNNjEBFRIwlUpk2bpoZwLrjgAjRt2tS2ff311548rIbFaARang0Mewl4cDtwx2JgwEQgth1gLgJ2LwR+mgi81hFjd92Fe/x/RNbuVViyaZ/bD1XakD9faQ0q7h6YDIMEXKWuLR3+mb/lGLIKHB+amrF8P7ILS5AUGaRuL9lxHIdP1a4o92hGPoa+uQwj3v0T+UXmWj0GERG5lj88iMWP9RC0NO9j3S6aDJz4B9jxE7DjZ+DIWgSlrMOj/uvUq2757mlYlraBsUkXoElX65bQFYhpY50ttxrFZouqM5HhpEu6WedoccTs1QeRVVCC5LhQXNSl7PdJhqVdQhh2p+bg503HcMNZLWt8vOyCYnzy5151/T/DO2PmXwfVDLxf/XUQj17SCc6SnymvyKw2CZiu6lV1vRQREflAoEL1LL4DEP8gcN6DQNZRYOcvMO+Yj4w9axGLDODUXusmwYzOPxiI7wg07wskXwC0PhcIjirzsK8s2Kk+1MXLV/fAdX1r7r6S4Z6P/7Bmccaenww/4+lsipDsihTVTp2/Q82p4kigIsM8Evi0jQ/FsG5N4W80qEDl6zWHMGFIezWk5EztzKzVB223Z685xECFiMgLMFDxpRWb+94Bv753YPuuNEz45H/oZDyEqef5oUXRPuD4ViB1B1CSDxzbYN3WfGSdwyWplzVoSb4AC7Nb2YIU8dh3mxAa6G9b/LAqUheTklWA+PBAjDyzWaX7XHVmMxUErT+YgT0nclTGpioy5b4U0Yrxg9upwOfCzk3QNDIIxzILVEbkyjMdDzQ+Xb4PhSUWldXZeyIHq/elq0uZg4aIiHy8PZnc69z2cRjYqwuWW7rhjh1noWj4O8DY34D/HAHuWw9c+xnQ904gtr113aEja4E/XgU+uwznftcbn5mm4qO2KzCpy0nEaJmY+PV6LN2ZWuXzScvwB6XT5d82oE2VmY6EiCAM7BDvUFHtV38dQHpuEVrHhmBED2shrr+fETeWZmKcKaqVdu0vSveXIaNBHRPUdcnMEBGRZzGj4qOeGN4Fv+08gZ3Hs/HRH3sxblA7a21KbFvr1nWkdcfMw8De32He8xsyty5EjHYKA/02AUc2qS/fFQRkaSHYP7MpTrTtjvhWXa2FvGprCwSEYsmOVOxKzUFYoD9GnV39kI4U1cr+360/jIcv7lhhiEgUFJvx4TJrNuXeQe1UgKK7/qyWeHvJLvx9MANbjmSiW7PIGs/FZyv3q0Lfjk3CMaRTgqqdWrwjFf9dfxgPXdwRAf6M54mIPIW/gX1UTGgAnrqsi7r+1uJdapijUpHNgTNHYbJpAnrlv4urDa8jc+BzQIdhQFQraDAgwpCHHoY9iN87D1j6AvDtrcAH5wEvJgHv9UPBT4/iPOMmjO6bgIggU7XHNaRzE0SHmHA8qxDLdp2odB+pJUnLKUTz6GBcWW4YSYaWpF5F6B1G1ZEhJBn2EfcOaguj0YBBnRLU46TlFKkuIiIi8hwGKj7sijOScH6HeFXo+p+5m6vswvpx49HSoRQDxl8/ApGD7gdunA1M3ATD4ykoHLscr0c/iZeKr8f3uAD5TfoAwaULS57Ygcvy5uKLgKl4+O9LgC+uAla+B5zYKW1fFZ5LshdXnNGsyuEfyaboqy7fe0E7mOyyKbpb+rdSl99vOFrjIowS9GTkFashpMtKh5DkMfXZcqWoloiIPIeBig+TTpsXRnZDkMmIVXvTMWdtxcBAMi2P/dc6zDNuUFtb/YaNKQiBSd0w9u6JWJl0CyYUjMX56ZOw//YtwL/3YFrCU5hdcgEy/eNhMBcAexYDC/4DvHcW8EY34If7gLWfAjt/BY5uAHJScU0va8CwcOvxCoGGzGor2RYpmr26t102xS7o6d0qWk3NL8Wxlf1MZYeQ9tpmybUfZrquj7WT6fd/Tqj5VYiIyDMMWgOezERWT5bFCWXSOJ+aTt/FPly2By/+sgORwSYsenCgGvYQMunZlf+3HDtSstUssl/d0a9MPUh5ElRc/+EqtX+zqGBMvbo7bv5ktZpId9ED56MtDgO7FwO7FwEHVgDmKhZTNPrjhBaFw+YoxCS2RKtWbVX9jLkgG8s274FfcS46xxgQH1AEFOYAhdlAUbZ1mKrTCKDL5Zh1LBGT5m5Fq9gQLH3oAjWkU96Xqw7giXlbVNDz+78HVahFuf7DlSqAe+DCDphwYfu6nmYiIqrF5zcDFUKJ2YKR/7ccW45k4bIeTfHujb3U/Y98uxHfrD2MuLBA/HL/uaorx5H5SK77YCX2peWqAEXeXRd3aYIPb+lTdseiPGuwsmcJkL4HyD4GZKeojApQ97ekJawJvsnpie+L+uKum2/CBZ2tWRr7SesGvfobDp/Kx9MjuuDWARXXmfp+wxFMmL1BBV3LHhlUaWEvERE5j4EKOU06ZC5/90+1qvGnY/rgZE4R/v3tJshn85d39MM5beMcfixZIPDaaStwtHTNnO/uPQe9WkY79s3mYhWsZJ44hMdmLECclo4JZ4WpAtuPVp/AkTx/XHhGOwzsngwEhAGB4UBgBBAQAhxZB2z7AfjnV+uaR6WyjREI73k50PkKIHkg4B+ouooe/GYjYkMD8OejgxEc4Ffp0FC/Fxer9YQ+v+0sVc9DRETu/fxmezIp0sZ7+7lt8NEf+zDpu83qw1nIsIczQYqQDMRXd56NOz5bgx7NoxwPUoSfCYhshsjIZrB09McXW48j0K8NOsVEYGr2RsSFBeA/VwwGKgks1KR2nUcAJYXAvmXIWv9flGz7ETGWLODvL62b0QQtoTOCTibiJr9mOKPHQAQbpA4muMLDyXwv0lU0Y8V+NacKAxUiIvdjRoVs8opKcPEby9RwiJAP5hlj+lZa3+EOi7Ydxx2fr1VZj4hgkxpOemxYJ1X46qjRH69A0d4/8XDzHeidtxzISam4k8EPiO8ENO0JJJ0BJHQGotuowGf78VwMe+sPmPwMWDVpCGLDrPU7RERUexz6oVqTLpfRn65WBaY/3XeuRz+YpXbm7ClL1JwpQoZ/ZJhGpux31P+2pmDsF+vU9658bDACcw/jxU++RmTGVgyPS0Wbol1AXlrl3+wXAES1xLqsSGzJj0HHzt1xdu8+QHRrICYZMFXMwhARUc049EO1JlPY/3z/uarzx9PZA+kwuqpXM1sLsQxNOROk6BPIyVCU1M38tDkFcWEh+CitG4JNPXHjnYOBEJN1wUa1vtFGa4v0yV1AxkHAXASc3I3e0vIsT7trIbCr9IFlDaS4DkBiDyCxO9BULnsAIaXzxxARkUswUKEKuibVPO28u8iU+rL4YHiQP245p7XT3y+dOjf2a6kWO/xi5X5bC7LcJ7PzKpHNrFun4ae/0WIGso4A6ftQcGIPPv/5NyRpxzEoIRehuQeBgkw1mZ3aNn9z+vsimp8OXCTzEhBq3Uyll2oLK70vBDByKiMioupw6Ie83vqDp9QcL9WtplydkzmF6D9lCYrMFnU7wM+IPx4dhCYOtFvr/j1no5psTmasffWaHtZ26pTNwLFNQErpdqrmKfsrCI62zv8S2aJ0aw5E2V0PTag5mNH/C0s/OBFRA8ChH2pUnOoaqoQMYQ3v0RRz/z6ibl/Tp7lTQYq4/qwWKlD5edMxPDWiCyKkw0i2DkNP7yRZluNbkb1vHQ5s+wthxSfRLMQMkzkPKMq1zh2jLmVdpdLgIv+UdZOgp6o6GWm/1syyDLV1NWt13Xz6Uh7LP8h6PBHNSrfS45NgR78/JJbBDDUasiq7pwr9yb0YqJBPuLl/KxWoyFDQ3ec73jVkHyy1SwjD7tQctfbRqH7W9YTsHSsMwAcbIzFzdTsUlSSr+4JNfhh9TmuMPT/59FCTZECK860BS24akHnIumXI5eHS7ZA1ayN1MlUV+9orKQDS91q3KlhgUAGNUR92kmJgmX9Gvy6XQRFAeFMgrIn1Um1NrLeldZzIw8wWDc/9tA3frD2kOgDHD2rHgKWR49AP+Yw5aw+pNuehXRNr9f0f/7EXz/+8HT2aR+KH8efa7pdC3Wm/7cY3aw7bhpdkvSGZ/XbT4Ux1OzTAGrDceV4yovWAxZHJ76TQVwIaaaE2+qFEM6iW6VX7M7Fi7ylsOZYDs2ZEqCEfTZGOREM6kgwn1WVTtZ1Ul/EG63HUngEIjQPCEoGIpnbDVC1PD12FJ6pjJKovsqzHfbP+xqLtp1c1v6hLE7x+XU+E17AyO3kXticT1QOpdTl7ymIUmzXVGRURZML//bZbrfIs94mz2sRg4pD26N82Vt1esiMVbyz6Ry1PIMIC/XHrgNa449xkRErHkQOOZeZj2T8nVOv4n7vSkFVQUubrnRLD1YR9kr2RYuFAtfkh0GR3HcXYuPsA/th2ECZLAYJRiGahGi7tFImBrUMR7lcMFOdZh6HUUgbHS5c1OG6de8ZS9jkrZfQvHW5qCYREWzNHarOU3WSoSi5lWCsswRr8qAxOaeZG3yTbQ1QqPbcIt3+2Bn8fzFDv81H9WuKrVQfVHwfJ8aH48OY+KutJDQMDFaJ6Mm7melWn0iYuFIfS81Aiaw4AOKdtLO4f0h5nJ1sDFHvyX2zhtuN4c9EubDtmDVjCJWA5tw0u6ZqIU3lFaq4YWScpLcd6Xd/kPlkt2p4UFp/bPk61kp/fPh6JkY7X26RmF6hf7l/9dUA9l5Bf+iPPSFLrHcmq0xVIbUx++un1mLKOQMs4hOL0gzCfOghD1mEE5KbAqDkQzDhDanOk3Vs6pmzDVJVcl+EqKTpWAY5cJgCh8U4NVUn2SyY6zMovRlZBsZqZOSu/xHpZINet90nQd1nPpuq8V1j7SX6VygKZEogFeU/nXGNw4GQuxkxfoyZ9lPf/x6P7oG/rGGw4lIG7v1iHlKwC9UfAa9f1rHXGlNyLgQpRPflj1wm1IrTuvPZxKkCRX5qOFP/9TwUs/6gVph0ln4c9W0RZA5MO8ejZPKrOCyQWlphVwDV9+X5sPnJ6WEhWm/a3e2ytivS7rAWlD3OpY4QFTXAKSYY0NDOkIcKQBw0GVRdjUV81WG9rpZcwqKULZEiqVUAOWgZkIcGYhRhLOkKL0uBnqWJlbWdI8bAELxK0yLCVag0Pt7WJZ1oCsC3Ngo3Hi7EupQSZRQb4G8wwwQx/lMAfZgSUXur3SyYqypCDZgH56BpVjJbBBQguzgTyTlo3i3XpCdWa3qz36U3m2PHCDJGs8SVDov8cz1HB74geSWgZ69xxykfI9mPZ+GnTUZXt8PcznM7kyaXJ7rq/UQ2/ynBNq9hQhx5/46EM3DZjDU7mFqk5kT677awymRMJ5uUPiNX70tXt+we3w8QLO7BuxcsxUCGqJxJsPD5vMzLyinHn+cm16kiSx/h1a4oaNpK/4mV1alnDSC5loj11KfeFW+9rFRPq8DCRs+S/v7R/f7p8P37dkqIKFZ0h89vYH7++BZmMyC0yI7ewxLqVXs8pLFFLNeQWmtUHjNyu5KgQhnwkGDKQ4JcLP0sBQlCoggQJbkJgHboKMch9RYg05CIOmYgzZCLRLxPRWhb8IN1Q3kMz+CE/uiNSwrriH/8O2IUWsPgFwehvgsHPBIO/CUa/AHXb6B8AP3UZCFNAgGqn14f05DLAzzrEJ5uc/9axoU4Frpl5xfh+4xG1ftXWo6cX79Sd0SIKl/dMUiupV7di+u7UbPy48ZgKUPacyHX6nMgwqbT7D+/etMqJHJfsOI5xX/2N/GIzuiZFYPqYvpUek2TEXvxluwq8xaCO8Xjz+jNV9oW8EwMVInJaalaB+sCx72C2//gzlH5BPjDjZObi0AC1cGNtya8eqTvYfzJPpfbLX0owqJMP4qhgkwrY5DIqJMB2O6egRAVb+oel5GuikYN4QwZaBuTgzJgixBhzkJqWDn9zHkKRj1BDIUJRgCbBZiQGlSDavxhBxhIYjCZrQbAMG8l1del/+rYpCOagaOzNDcSqFGBtqgEntXCc0sJRaIrE2d064NzkCJgPr4ffsfWIzdiCNoXbEYeMWp2jQs0f+QhEnmxakPUSQcjTrPflaMHI8IuGKaIpIuOboUmzVmjdOhnNmreGMTC0THC8cu9J1Skzf0sKikpOzyl0Udcm6NMqGou3p2LFnjS1grqQ2EdqrSRouaRrU3WuD57Mw4+bjqrON/usoARNEhwM6dQEJn8DCostKCyRzVz2eolFDd/8uTvNNv1PSIAfLu3eVE3uKMGL/j6btfognpi3RQXPkkn8v1G91PBOdeb+fRiP/Xezep7WsSH44OY+6JgYXqtzT/WLgQoRNXgZeUXILihRH5BS06N/gFW3/9+HMrD+wCkVuGw4mKEyOfYkuJIhtIEdrfU9DndgVVPo/N36IyoAOHAyr4q9NCQiHQPDDuKcoAPoht1IKD4Co6UERq249LIEfpoZRhdmgvINIcgPjEWBKQoncktQUKLBolmH4UIC/ZEQEaw2k39pIBYcjTy/CGzL9Mfq48Cmk37IQBhOaWHINkYgMiYB20/IkJz1dZAhQgkgJPMiQznOdN3o500K0SVw0bWMCVFZFsmgTPttj7pPbk+5qjtMfo7N4rzlUDoe+HIlTmVmIsSkITaxFRIjg9XcSVLPlRgRVOZ6cGUrsTdgZoumhvQ2HclE8+hgnNE8qs7v8/rAQIWIfJ78wt6Zko11B0+pYScpeO6WFFkvtQvya3TN/lMqYNl1PBstYkKQHB+GtvGhSI4LQ5v40BqzAbbCZemwklqXkkJrJ5aaKDCnkuu5sORnIivtMHJOHoU56zgC81MRaU5XQ2T1wawZUGQMgsEUjICgUBgD7ObgUZfB1qDHL7D0MsC6+Zdeyib7qDb3JGjhTbH+VDC+2XBCDSGVDyyl3uSBC9vDIN1o+jxB+ibzDalzkW89H/r5MZetb8rUQrDJkozNWrL10tIGRxBnC7hkeCgpKljVv8gHu2xyvZm6HqIWNNWDZMlMSXG1ZAKlCD49txincouQnlekMoD5RSUoKLaoQEu2AttmvU+ySgYYVLZK3odGgwF+BoPKYkrWUDYJAKUGRzr5ZDmTLk0jagymDp/Kwx+70lRX4PI9aWWykUKySzKkJ9uZLaNV0by+nIinMFAhIvJRxSVm7D6cgr179+Dw4QPQck/ijBYROLNFJAL9DKVt4lrZVnEJitQsyelAXummX89Ph5Z/Cga1fz0JjoElPAmpiMGWnDAczPXHkKQitEKKWm8Lhc7PAyRF27J4qEFmcC4nAxEqcNlgbo0tltY4qsUhVYtCGiJhRtmgQNr+EyICVbB7Kq+4XB2XhkjkqvqoaGSjAAHIRTBytCB1KcNzZQdQnWc0wBq4JEWia7NIdEuKUF2H0vEkQ2gSoNhnpYRkIM9oGaU6E2UotTwJUqTmRwrzJTCLDQtAbKgsRGutNZPJKR3NYNUWAxUiInIdyfQUZllnQFbZi/xyW97pr8lEhTKjsgQ/+nX7TZaRKG1zR9YxoCTfsWOQZSBikoGYNtZLmWwwMLLcDMulm9yWZSXk+U9sB47+fXo7vrXKeYEkuMn2i8JJQzSOmSNxuDgCqYhSw19RpUXbUvuUaMxCvDETMVoGTKi6LV+DESX+ITCbQmExhUELCINm9FP3a0Z/1REnhdaawVh63R/F8ENqSSj2FoRhW3Yw9hWE4oQWpTYJpIormVBeMjGSLZEuRNkkAFHdewaDyvhsPJyhAht9K59xqYxkmlTgEhqoHvO+Ie3hSgxUiIjI+8nHj5pk8Jh1FmZ9K8iwznasByXS7i0BiSsUFwCpW08HLilbrIFTbmpplqkWZN6c4BhrcCbDUfp8OvUgE2FIs4SrjEeYSUOwn4ZAoxlGGS40lw4bSoAmmSQVtIUBgeFAoFxGQAsMQ64WjNSiAKQU+ONUcQDSS0xIL/JHaqEJJwqNKiOUrwUiVwq3EYjzu7fDizee59Kfg4sSEhGR95PiDJnUT7YmXd3znKag0/Pb2JMFPmXtLZmJWZ+RWb+UYEpWOtcnFbSfYFDm6ZHHtKfW88oDCkuDlqJs63XJJkk2Ry0oKkGF3SKj+v0SZKjjkOdOLXtpKUYkchBpzLHGQTWVIum1OxKElZKBqLDSLbnS81PxrvTCYTJrFDyFgQoREZG0pcsyDrI1dUEAVjqxoHo8V2afco5bAxmDsWL7vCpgLr0uP4++WrsESypoyrK7rQdPp4uz1WZ/vfR2THTNE1rWJwYqREREDSn75G4erhDxbH8SEREReTeDZ5cjYKBCREREXouBChEREXktBipERETktRioEBERkddioEJERERei4EKEREReS0GKkREROS1PBqoLFu2DCNGjEBSUpJaRnvevHmePBwiIiLyMh4NVHJzc9GzZ0+89957njwMIiIi8lIenUJ/2LBhaiMiIiKqDGtUiIiIyGs1qEUJCwsL1abLysry6PEQERFR/WpQGZUpU6YgMjLStrVo0cLTh0RERET1qEFlVCZNmoQHH3zQdjszMxMtW7ZkZoWIiKgB0T+3NU1rXIFKYGCg2sr/oMysEBERNTzZ2dlqhMRrA5WcnBzs3r3bdnvfvn3YsGEDYmJiVKakJjL/yqFDhxAeHq7mYXElCYIkAJLHj4iIcOlj02k8z+7B8+wePM/uwfPc8M+1ZFIkSJHP8Zp4NFBZu3YtBg0aZLutD+uMHj0aM2bMqPH7jUYjmjdvXq/HKC8M/yPUP55n9+B5dg+eZ/fgeW7Y57qmTIpXBCoXXHCBQ+NTRERE5JsaVNcPERER+RYGKlWQot2nn366TPEuuR7Ps3vwPLsHz7N78Dz71rk2aBx7ISIiIi/FjAoRERF5LQYqRERE5LUYqBAREZHXYqBCREREXouBSiXee+89tG7dGkFBQejXrx9Wr17t6UNq8JYtW4YRI0aoWQhlFuF58+aV+brUdD/11FNo2rQpgoODceGFF2LXrl0eO96GSBbt7Nu3r5qpOSEhASNHjsTOnTvL7FNQUIBx48YhNjYWYWFhuPrqq3H8+HGPHXNDNW3aNPTo0cM2CVb//v0xf/5829d5nl1v6tSp6nfHxIkTbffxPLvGM888o86t/dapUyevOc8MVMr5+uuv1Qy50o61fv169OzZE0OHDkVqaqqnD61By83NVedSgsDKvPzyy3j77bfx/vvv46+//kJoaKg67/IfhBzz+++/q18mq1atwsKFC1FcXIyLL75YnXvdAw88gB9//BFz5sxR+x89ehRXXXWVR4+7IZIZseWDc926dWqG7cGDB+OKK67A1q1b1dd5nl1rzZo1+OCDD1RwaI/n2XW6du2KY8eO2bY///zTe86ztCfTaWeddZY2btw4222z2awlJSVpU6ZM8ehxNSbytps7d67ttsVi0RITE7VXXnnFdl9GRoYWGBiozZo1y0NH2fClpqaqc/3777/bzqnJZNLmzJlj22f79u1qn5UrV3rwSBuH6Oho7eOPP+Z5drHs7Gytffv22sKFC7WBAwdqEyZMUPfzPLvO008/rfXs2bPSr3nDeWZGxU5RUZH6C0mGHezXE5LbK1eu9OixNWayGGVKSkqZ8y5rQMiwG8977WVmZqpLWeRTyHtbsiz251nSu7IAKM9z7ZnNZsyePVtlrmQIiOfZtSRLOHz48DLnU/A8u5YMtcvQfHJyMkaNGoWDBw96zXn26Fo/3iYtLU390mnSpEmZ++X2jh07PHZcjZ0EKaKy865/jZxjsVjUWP6AAQPQrVs3dZ+cy4CAAERFRZXZl+e5djZv3qwCExmelHH7uXPnokuXLmoFeJ5n15AAUIbgZeinPL6fXUf+KJSFgDt27KiGfSZPnozzzjsPW7Zs8YrzzECFqJH+FSq/ZOzHmcm15Je6BCWSufr222/Vqu8yfk+ucejQIUyYMEHVW0ljA9WfYcOG2a5LHZAELq1atcI333yjmhs8jUM/duLi4uDn51ehmlluJyYmeuy4Gjv93PK8u8b48ePx008/YenSparoUyfnUoY3MzIyyuzP81w78ldmu3bt0Lt3b9VxJcXib731Fs+zi8iQgzQx9OrVC/7+/mqTQFCK7uW6/EXP81w/JHvSoUMH7N692yvezwxUyv3ikV86ixcvLpNCl9uS4qX60aZNG/WGtz/vWVlZqvuH591xUqcsQYoMQSxZskSdV3vy3jaZTGXOs7Qvy1g0z3Pdye+KwsJCnmcXGTJkiBpek6yVvvXp00fVT+jXeZ7rR05ODvbs2aOmi/CK97NbSnYbkNmzZ6tukxkzZmjbtm3Txo4dq0VFRWkpKSmePrQGX7n/999/q03edq+//rq6fuDAAfX1qVOnqvP8/fffa5s2bdKuuOIKrU2bNlp+fr6nD73BuOeee7TIyEjtt99+044dO2bb8vLybPvcfffdWsuWLbUlS5Zoa9eu1fr37682cs5jjz2muqn27dun3q9y22AwaP/73//U13me64d914/geXaNhx56SP3ekPfz8uXLtQsvvFCLi4tTnYPecJ4ZqFTinXfeUS9KQECAaldetWqVpw+pwVu6dKkKUMpvo0ePtrUoP/nkk1qTJk1UoDhkyBBt586dnj7sBqWy8yvb9OnTbftI4HfvvfeqVtqQkBDtyiuvVMEMOee2227TWrVqpX5HxMfHq/erHqQInmf3BCo8z67xr3/9S2vatKl6Pzdr1kzd3r17t9ecZ4P8457cDREREZFzWKNCREREXouBChEREXktBipERETktRioEBERkddioEJERERei4EKEREReS0GKkREROS1GKgQUaNiMBgwb948Tx8GEbkIAxUicpkxY8aoQKH8dskll3j60IiogfL39AEQUeMiQcn06dPL3BcYGOix4yGiho0ZFSJyKQlKZDVs+y06Olp9TbIr06ZNw7BhwxAcHIzk5GR8++23Zb5fVswdPHiw+npsbCzGjh2rVnO19+mnn6Jr167quWSFV1k12l5aWhquvPJKhISEoH379vjhhx/c8JMTUX1goEJEbvXkk0/i6quvxsaNGzFq1Chcf/312L59u/pabm4uhg4dqgKbNWvWYM6cOVi0aFGZQEQCnXHjxqkARoIaCULatWtX5jkmT56M6667Dps2bcKll16qnic9Pd3tPysRuYDblj8kokZPVsP28/PTQkNDy2wvvPCC+rr8ypEl4+3169dPu+eee9T1Dz/8UK3QmpOTY/v6zz//rBmNRi0lJUXdTkpK0h5//PEqj0Ge44knnrDdlseS++bPn+/yn5eI6h9rVIjIpQYNGqSyHvZiYmJs1/v371/ma3J7w4YN6rpkVnr27InQ0FDb1wcMGACLxYKdO3eqoaOjR49iyJAh1R5Djx49bNflsSIiIpCamlrnn42I3I+BChG5lAQG5YdiXEXqVhxhMpnK3JYAR4IdImp4WKNCRG61atWqCrc7d+6srsul1K5IrYpu+fLlMBqN6NixI8LDw9G6dWssXrzY7cdNRJ7BjAoRuVRhYSFSUlLK3Ofv74+4uDh1XQpk+/Tpg3PPPRdfffUVVq9ejU8++UR9TYpen376aYwePRrPPPMMTpw4gfvuuw8333wzmjRpovaR+++++24kJCSo7qHs7GwVzMh+RNT4MFAhIpf69ddfVcuwPcmG7Nixw9aRM3v2bNx7771qv1mzZqFLly7qa9JOvGDBAkyYMAF9+/ZVt6VD6PXXX7c9lgQxBQUFeOONN/Dwww+rAOiaa65x809JRO5ikIpatz0bEfk0qRWZO3cuRo4c6elDIaIGgjUqRERE5LUYqBAREZHXYo0KEbkNR5qJyFnMqBAREZHXYqBCREREXouBChEREXktBipERETktRioEBERkddioEJERERei4EKEREReS0GKkREROS1GKgQERERvNX/A4cNgLe+FQBgAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load all history files\n",
        "history_files = sorted(glob.glob('GNN_MODEL/history_epoch_*.pkl'))\n",
        "\n",
        "full_history = {}\n",
        "for file in history_files:\n",
        "    with open(file, 'rb') as f:\n",
        "        epoch_history = pickle.load(f)\n",
        "    for key, values in epoch_history.items():\n",
        "        full_history.setdefault(key, []).extend(values[len(full_history.get(key, [])):])\n",
        "\n",
        "# Plot\n",
        "\n",
        "\n",
        "plt.plot(full_history['val_loss'])\n",
        "plt.plot(full_history['loss'])\n",
        "plt.title('Model accuracy over all epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
